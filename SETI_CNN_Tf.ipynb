{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.cognitiveclass.ai\"><img src = \"https://cognitiveclass.ai/wp-content/themes/bdu3.0/static/images/cc-logo.png\" align = left></a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "--------------------\n",
    "# SETI CNN using TF and Binary DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn)\r\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "#import ibmseti\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time\n",
    "!sudo pip install sklearn\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set your team folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/SETI1_data\n",
      "/tmp/SETI1_train\n"
     ]
    }
   ],
   "source": [
    "### SET YOUR TEAM NAME HERE! Use this folder to save intermediate results\n",
    "mydatafolder = \"/tmp/SETI1_data\"\n",
    "if os.path.exists(mydatafolder) is False:\n",
    "    os.makedirs(mydatafolder)\n",
    "print mydatafolder\n",
    "\n",
    "train_dir = '/tmp/SETI1_train'\n",
    "if os.path.exists(train_dir) is False:\n",
    "    os.makedirs(train_dir)\n",
    "print train_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Import dataset reader\n",
    "The following cell will load a python code to read the SETI dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-08-25 04:54:08--  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n",
      "Resolving ibm.box.com (ibm.box.com)... 107.152.27.197, 107.152.26.197\n",
      "Connecting to ibm.box.com (ibm.box.com)|107.152.27.197|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://ibm.ent.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip [following]\n",
      "--2017-08-25 04:54:08--  https://ibm.ent.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n",
      "Resolving ibm.ent.box.com (ibm.ent.box.com)... 107.152.26.211, 107.152.27.211\n",
      "Connecting to ibm.ent.box.com (ibm.ent.box.com)|107.152.26.211|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://public.boxcloud.com/d/1/98d7nC9RLwLKa1ki_-a0ZHMCy1um3cSYzD1DdFHzZM3RyNudAlxtr3Dn_4YCGX-LKqifvX-c1wSH0fuKfU2LAhQ049aihCliOAibmlrNt2VSWgitXTx0EYVqGUX7s3OGkcvpYJ0A8aThuFLdKP4xNq_N9gdkzurwZ-uwiYX7sq3g3VWZLmBfIxlN7VjmnqV473jryBhpw35gWDqlGewJ-byiiXBaxguecDMIkfYIQCdXcO40sDJprnKT2X2pkRbUzPgN9Aw4BNiGqAFUjFhkIObua4RTQuhg7HQQpovp8mTDz9v_1-r74rSOymA_9kch8H3ZgsNzX6zUrckDjGuoTISdIW-tpq1LKLlLb6f42lzt9csSvWzbyyuG8dtjLoOXNKt46A21iz0dS8BMEXtWkSbJHx5cQyHHIZeGysZdOZS9q-gmuSEzUG93RDOG3xZdLVHwSU8V5AxhFkEzTtpk46kM8z8DFrz0SSCXUEfcPo3_e3EeFI4YVfs-5l31dVChz58C37mESm1mwAaAOLTwiR_52tijl0u7dwKpD3TdepKKkRt-gUO4Z3tMUgfgGaGknVCTo4JKV25IEQkxrLKvgoL6rpZ8Rr_PIgSKQ1afffkL63FAovX23PHxuUydSiLB8X7O2AIC-j5YLvcjkIcMQasVwaySM6eC-wAQLjFpjaJhCzD3t9XGaT8sa9Y765BKKrrBGH3UC5mD3Q2H6rTw566HWjJ5elrUf9FNqwXn97pPpRl7PsA2hg-VXemoK_jg6Y87d6nEj2SudsXp72Qwyu8gfD-rFxeRogVfZifo29YlQyhD3wNAX88vrW8QCoOKGA49DEQk6NZ02amitIaf6TqnCtwpOvQnpleo0gH16QtpFukgm2CC2AVl7E0NOnUhooAWlZJE-GaUH4vcESUUXse0SDJQvSDDo-fo05YfwESgkHkBPY2xGDPpEjztZRxf9zA4LyXJa7-z_55d_5wsOV_6yj8WlSqcdSSJyt2pVJhPp6K_Fp88qGiEjvmGvt2tV59OjNzwmx3pSOYNgvFl-v9yul2Ypju56cHoIOWVz6OaJ6FeB4kRDdfx3HBT7KztLDQyc0DmoXG82m8jlvF-S3qDjrQBzUGV2-a1HqZu6TLzOjXDflNl2C6PKY3sHPH1SS9PBknWE9565Mcq9WnmB6k./download [following]\n",
      "--2017-08-25 04:54:09--  https://public.boxcloud.com/d/1/98d7nC9RLwLKa1ki_-a0ZHMCy1um3cSYzD1DdFHzZM3RyNudAlxtr3Dn_4YCGX-LKqifvX-c1wSH0fuKfU2LAhQ049aihCliOAibmlrNt2VSWgitXTx0EYVqGUX7s3OGkcvpYJ0A8aThuFLdKP4xNq_N9gdkzurwZ-uwiYX7sq3g3VWZLmBfIxlN7VjmnqV473jryBhpw35gWDqlGewJ-byiiXBaxguecDMIkfYIQCdXcO40sDJprnKT2X2pkRbUzPgN9Aw4BNiGqAFUjFhkIObua4RTQuhg7HQQpovp8mTDz9v_1-r74rSOymA_9kch8H3ZgsNzX6zUrckDjGuoTISdIW-tpq1LKLlLb6f42lzt9csSvWzbyyuG8dtjLoOXNKt46A21iz0dS8BMEXtWkSbJHx5cQyHHIZeGysZdOZS9q-gmuSEzUG93RDOG3xZdLVHwSU8V5AxhFkEzTtpk46kM8z8DFrz0SSCXUEfcPo3_e3EeFI4YVfs-5l31dVChz58C37mESm1mwAaAOLTwiR_52tijl0u7dwKpD3TdepKKkRt-gUO4Z3tMUgfgGaGknVCTo4JKV25IEQkxrLKvgoL6rpZ8Rr_PIgSKQ1afffkL63FAovX23PHxuUydSiLB8X7O2AIC-j5YLvcjkIcMQasVwaySM6eC-wAQLjFpjaJhCzD3t9XGaT8sa9Y765BKKrrBGH3UC5mD3Q2H6rTw566HWjJ5elrUf9FNqwXn97pPpRl7PsA2hg-VXemoK_jg6Y87d6nEj2SudsXp72Qwyu8gfD-rFxeRogVfZifo29YlQyhD3wNAX88vrW8QCoOKGA49DEQk6NZ02amitIaf6TqnCtwpOvQnpleo0gH16QtpFukgm2CC2AVl7E0NOnUhooAWlZJE-GaUH4vcESUUXse0SDJQvSDDo-fo05YfwESgkHkBPY2xGDPpEjztZRxf9zA4LyXJa7-z_55d_5wsOV_6yj8WlSqcdSSJyt2pVJhPp6K_Fp88qGiEjvmGvt2tV59OjNzwmx3pSOYNgvFl-v9yul2Ypju56cHoIOWVz6OaJ6FeB4kRDdfx3HBT7KztLDQyc0DmoXG82m8jlvF-S3qDjrQBzUGV2-a1HqZu6TLzOjXDflNl2C6PKY3sHPH1SS9PBknWE9565Mcq9WnmB6k./download\n",
      "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.26.200, 107.152.27.200\n",
      "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.26.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3288 (3.2K) [application/zip]\n",
      "Saving to: ‘SETI.zip’\n",
      "\n",
      "SETI.zip            100%[===================>]   3.21K  --.-KB/s    in 0s      \n",
      "\n",
      "2017-08-25 04:54:10 (127 MB/s) - ‘SETI.zip’ saved [3288/3288]\n",
      "\n",
      "Archive:  SETI.zip\n",
      "  inflating: SETI.py                 \n",
      "  inflating: __MACOSX/._SETI.py      \n"
     ]
    }
   ],
   "source": [
    "!wget --output-document SETI.zip  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n",
    "!unzip -o SETI.zip\n",
    "import SETI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "import sys\n",
    "import tarfile\n",
    "def maybe_download_and_extract():\n",
    "    data_dir = \"/tmp/SETI1_data\"\n",
    "    DATA_URL =  'https://ibm.box.com/shared/static/qz33lcio9ip2j8qi2atxqs62gn3bnu2s.gz'\n",
    "    dest_directory = data_dir\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "        sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    extracted_dir_path = os.path.join(dest_directory, 'SETI_ds_64x128')\n",
    "    if not os.path.exists(extracted_dir_path):\n",
    "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "('Successfully downloaded', 'qz33lcio9ip2j8qi2atxqs62gn3bnu2s.gz', 2432541, 'bytes.')\n"
     ]
    }
   ],
   "source": [
    "maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Load data SETI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/test-images-idx3-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/test-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(694, 8192)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_directory = mydatafolder + '/SETI_ds_64x128/'\n",
    "dataset = SETI.read_data_sets(ds_directory, one_hot=True, validation_size=0)\n",
    "dataset.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "decay_rate=0.96\n",
    "decay_steps=1000\n",
    "learning_rate = 0.005\n",
    "training_epochs = 3000\n",
    "batch_size = 50\n",
    "display_step = 100\n",
    "\n",
    "#check point directory\n",
    "chk_directory = train_dir+'/save/'\n",
    "checkpoint_path = chk_directory + 'model.ckpt'\n",
    "\n",
    "\n",
    "n_classes = 4 # number of possible classifications for the problem\n",
    "dropout = 0.50 # Dropout, probability to keep units\n",
    "\n",
    "height = 64 # height of the image in pixels \n",
    "width = 128 # width of the image in pixels \n",
    "n_input = width * height # number of pixels in one image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "x  = tf.placeholder(tf.float32, shape=[None, n_input])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(?, 64, 128, 1) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_image = tf.reshape(x, [-1,height,width,1]) \n",
    "x_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Convolutional Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool:0' shape=(?, 32, 64, 32) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[32])) # need 32 biases for 32 outputs\n",
    "convolve1 = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1\n",
    "h_conv1 = tf.nn.relu(convolve1)\n",
    "conv1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\n",
    "conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Convolutional Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_1:0' shape=(?, 8, 16, 64) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[64])) #need 64 biases for 64 outputs\n",
    "convolve2= tf.nn.conv2d(conv1, W_conv2, strides=[1, 1, 1, 1], padding='SAME')+ b_conv2\n",
    "h_conv2 = tf.nn.relu(convolve2)\n",
    "conv2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 4, 4, 1], padding='SAME') #max_pool_2x2\n",
    "conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Convolutional Layer 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "W_conv3 = tf.Variable(tf.truncated_normal([5, 5, 64, 128], stddev=0.1))\n",
    "b_conv3 = tf.Variable(tf.constant(0.1, shape=[128])) #need 64 biases for 64 outputs\n",
    "convolve3= tf.nn.conv2d(conv2, W_conv3, strides=[1, 1, 1, 1], padding='SAME')+ b_conv3\n",
    "h_conv3 = tf.nn.relu(convolve3)\n",
    "conv3 = tf.nn.max_pool(h_conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\n",
    "conv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Convolutional Layer 4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "W_conv4 = tf.Variable(tf.truncated_normal([5, 5, 128, 256], stddev=0.1))\n",
    "b_conv4 = tf.Variable(tf.constant(0.1, shape=[256])) #need 64 biases for 64 outputs\n",
    "convolve4= tf.nn.conv2d(conv3, W_conv4, strides=[1, 1, 1, 1], padding='SAME')+ b_conv4\n",
    "h_conv4 = tf.nn.relu(convolve4)\n",
    "conv4 = tf.nn.max_pool(h_conv4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Fully Connected Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 8, 16, 64]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = conv2\n",
    "dim = input_layer.get_shape().as_list()\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 1024) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims= dim[1]*dim[2]*dim[3]\n",
    "nodes1 = 1024\n",
    "prv_layer_matrix = tf.reshape(input_layer, [-1, dims])\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([dims, nodes1], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[nodes1])) # need 1024 biases for 1024 outputs\n",
    "h_fcl1  = tf.matmul(prv_layer_matrix, W_fc1) + b_fc1\n",
    "fc_layer1 = tf.nn.relu(h_fcl1) # ???\n",
    "fc_layer1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Droupout 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "layer_drop1 = tf.nn.dropout(fc_layer1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Fully Connected Layer 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "nodes2 = 256\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([layer_drop1.get_shape().as_list()[1], nodes2], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[nodes2])) \n",
    "h_fcl2  = tf.matmul(layer_drop1, W_fc2) + b_fc2\n",
    "fc_layer2 = tf.nn.relu(h_fcl2) # ???\n",
    "fc_layer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Droupout 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "layer_drop2 = tf.nn.dropout(fc_layer2, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Readout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "W_fc = tf.Variable(tf.truncated_normal([nodes1, n_classes], stddev=0.1)) #1024 neurons\n",
    "b_fc = tf.Variable(tf.constant(0.1, shape=[n_classes])) # 10 possibilities for classes [0,1,2,3]\n",
    "fc = tf.matmul(layer_drop1, W_fc) + b_fc\n",
    "y_CNN= tf.nn.softmax(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_CNN, labels=y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a variable to track the global step.\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "# create learning_decay\n",
    "# Decay the learning rate exponentially based on the number of steps.\n",
    "lr = tf.train.exponential_decay( learning_rate,\n",
    "                                 global_step,\n",
    "                                 decay_steps,\n",
    "                                 decay_rate, staircase=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Use the optimizer to apply the gradients that minimize the loss\n",
    "# (and also increment the global step counter) as a single training step.\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "\n",
    "train_op = optimizer.minimize(cross_entropy, global_step=global_step)\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_CNN,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Create checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: \"/tmp/SETI1_train/save/model.ckpt-36000\"\n",
      "all_model_checkpoint_paths: \"/tmp/SETI1_train/save/model.ckpt-36000\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directory = os.path.dirname(chk_directory)\n",
    "try:\n",
    "    os.stat(directory)\n",
    "    ckpt = tf.train.get_checkpoint_state(chk_directory)\n",
    "    print ckpt\n",
    "except:\n",
    "    os.mkdir(directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model:  /tmp/SETI1_train/save/model.ckpt-36000\n"
     ]
    }
   ],
   "source": [
    "loss_values = []\n",
    "\n",
    "X_test = dataset.test.images\n",
    "y_test = dataset.test.labels\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "# load previously trained model if appilcable\n",
    "ckpt = tf.train.get_checkpoint_state(chk_directory)\n",
    "if ckpt:\n",
    "    print \"loading model: \",ckpt.model_checkpoint_path\n",
    "    #saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 , g_step: 0013 , E_time= 0.76379 , lr= 0.005000000 , cost= 1.404944071 , Acc= 0.250769226\n",
      "Epoch: 0101 , g_step: 1313 , E_time= 0.23737 , lr= 0.004800000 , cost= 1.178780519 , Acc= 0.533846131\n",
      "Epoch: 0201 , g_step: 2613 , E_time= 0.22683 , lr= 0.004608000 , cost= 1.165302588 , Acc= 0.524615368\n",
      "Epoch: 0301 , g_step: 3913 , E_time= 0.23531 , lr= 0.004423679 , cost= 1.156065326 , Acc= 0.541538443\n",
      "Epoch: 0401 , g_step: 5213 , E_time= 0.22968 , lr= 0.004076863 , cost= 1.147864984 , Acc= 0.578461516\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-778960b837a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/DL/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/DL/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/DL/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/DL/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/DL/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#step = 0\n",
    "num_examples = dataset.train.num_examples\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0.\n",
    "    #dataset.shuffle_data()\n",
    "    total_batch = int(num_examples / batch_size)\n",
    "\n",
    "    # Loop over all batches in one epoch\n",
    "    start = time.time()\n",
    "    for step in range(total_batch):\n",
    "        x_batch, y_batch = dataset.train.next_batch(batch_size,shuffle=True)\n",
    "        sess.run([train_op], feed_dict={x: x_batch, y_: y_batch, keep_prob: dropout})\n",
    "        loss, acc = sess.run([cross_entropy, accuracy], feed_dict={x: x_batch,y_: y_batch,keep_prob: 1.})\n",
    "        avg_loss += loss / total_batch\n",
    "        avg_accuracy += acc / total_batch\n",
    "        \n",
    "        # Display cretria for batches in epoches\n",
    "        if step % display_step == 1000:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cross_entropy, accuracy], feed_dict={x: x_batch,y_: y_batch,keep_prob: 1.})\n",
    "            #train_accuracy = accuracy.eval(feed_dict={x:x_batch, y_: y_batch,  keep_prob: 0.5})\n",
    "            test_accuracy = sess.run(accuracy, feed_dict={x: X_test[0:100], y_: y_test[0:100], keep_prob: 1.})\n",
    "\n",
    "            print(\"Iter \" + str(step) + \\\n",
    "                \", Minibatch Loss= \" +  \"{:.6f}\".format(loss) +  \\\n",
    "                \", Training Accuracy= \" + \"{:.5f}\".format(acc)  + \\\n",
    "                \", Test Accuracy= \" + \"{:.5f}\".format(test_accuracy) )\n",
    "\n",
    "    # save model every x epochs\n",
    "    if epoch >= 0 and epoch % 100 == 0:\n",
    "        pass\n",
    "        # Save model\n",
    "        #print (\"model saved to {}\".format(checkpoint_path))\n",
    "        #saver.save(sess, checkpoint_path, global_step = (epoch+1)*step)\n",
    "\n",
    "    # Display model every 1 epochs\n",
    "    if epoch >= 0 and epoch % 100 == 0:\n",
    "        end = time.time()\n",
    "        plr = sess.run(lr)\n",
    "        g_step = sess.run(global_step)\n",
    "        loss_values.append(avg_loss)\n",
    "        #print(sess.run(tf.train.global_step()))\n",
    "        print \"Epoch:\", '%04d' % (epoch+1) , \", g_step:\", '%04d' % (g_step) , \", E_time=\" , \"{:.5f}\".format(end - start) , \", lr=\", \"{:.9f}\".format(plr), \", cost=\", \"{:.9f}\".format(avg_loss) ,\", Acc=\", \"{:.9f}\".format(avg_accuracy)\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "print (\"model saved to {}\".format(checkpoint_path))\n",
    "saver.save(sess, checkpoint_path, global_step = (epoch+1)*step)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate accuracy for test images\n",
    "#print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: X_test[0:30], y_: y_test[0:30], keep_prob: 1.}))\n",
    "\n",
    "# Find the labels of test set\n",
    "y_pred_lb = sess.run(tf.argmax(y_CNN,1), feed_dict={x: X_test[0:100], y_: y_test[0:100], keep_prob: 1.})\n",
    "y_pred = sess.run(y_CNN, feed_dict={x: X_test[0:100], y_: y_test[0:100], keep_prob: 1.})\n",
    "\n",
    "# lets save kernels\n",
    "kernels_l1 = sess.run(tf.reshape(tf.transpose(W_conv1, perm=[2, 3, 0, 1]),[32,-1]))\n",
    "kernels_l2 = sess.run(tf.reshape(tf.transpose(W_conv2, perm=[2, 3, 0, 1]),[32*64,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVzJLTDY1B/8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3bfd82886410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([np.mean(loss_values[i:i+5]) for i in range(len(loss_values))])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is depend on the number of epoch that you set in partametrs part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "y_ = np.argmax(y_test[0:100],1) # ground truth\n",
    "print metrics.classification_report(y_true= y_, y_pred= y_pred_lb)\n",
    "print metrics.confusion_matrix(y_true= y_, y_pred= y_pred_lb)\n",
    "print(\"Classification accuracy: %0.6f\" % metrics.accuracy_score(y_true= y_, y_pred= y_pred_lb) )\n",
    "print(\"Log Loss: %0.6f\" % metrics.log_loss(y_true= y_, y_pred= y_pred, labels=range(4)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CSV file for Scoreboard\n",
    "\n",
    "Here's an example of what the CSV file should look like for submission to the scoreboard. Although, in this case, we only have 4 classes instead of 7.\n",
    "\n",
    "#### NOTE: This uses the test set created in Step_5c, which only contain the BASIC4 test data set. The code challenge and hackathon will be based on the Primary Data Set which contains 7 signal classes, and different test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_output_results = mydatafolder + '/' + 'DL_scores.csv'\n",
    "with open(my_output_results, 'w') as csvfile:\n",
    "    np.savetxt(my_output_results, y_pred, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.popen(\"ls -lrt \"+ mydatafolder).read() # to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!wget --output-document utils1.py http://deeplearning.net/tutorial/code/utils.py\n",
    "import utils1\n",
    "from utils1 import tile_raster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#from utils import tile_raster_images\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "image = Image.fromarray(tile_raster_images(kernels_l1, img_shape=(5, 5) ,tile_shape=(4, 8), tile_spacing=(1, 1)))\n",
    "### Plot image\n",
    "plt.rcParams['figure.figsize'] = (18.0, 18.0)\n",
    "imgplot = plt.imshow(image)\n",
    "imgplot.set_cmap('gray')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "image = Image.fromarray(tile_raster_images(kernels_l2, img_shape=(5, 5) ,tile_shape=(4, 12), tile_spacing=(1, 1)))\n",
    "### Plot image\n",
    "plt.rcParams['figure.figsize'] = (18.0, 18.0)\n",
    "imgplot = plt.imshow(image)\n",
    "imgplot.set_cmap('gray')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "sampleimage1 = X_test[3]\n",
    "plt.imshow(np.reshape(sampleimage1,[64,128]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "    \n",
    "    # load previously trained model if appilcable\n",
    "    ckpt = tf.train.get_checkpoint_state(chk_directory)\n",
    "    if ckpt:\n",
    "        print \"loading model: \",ckpt.model_checkpoint_path\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    ActivatedUnits1 = sess.run(convolve1,feed_dict={x:np.reshape(sampleimage1,[1,64*128],order='F'),keep_prob:1.0})\n",
    "    plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 3\n",
    "    n_rows = 3\n",
    "    for i in range(9):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(ActivatedUnits1[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Authors\n",
    "\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "#### Saeed Aghabozorgi\n",
    "\n",
    "[Saeed Aghabozorgi](https://ca.linkedin.com/in/saeedaghabozorgi), PhD is Sr. Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients’ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
