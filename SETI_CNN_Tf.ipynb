{
    "nbformat": 4, 
    "metadata": {
        "language_info": {
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "file_extension": ".py", 
            "version": "2.7.11", 
            "mimetype": "text/x-python", 
            "name": "python", 
            "nbconvert_exporter": "python"
        }, 
        "kernelspec": {
            "name": "python2", 
            "language": "python", 
            "display_name": "Python 2 with Spark 1.6"
        }
    }, 
    "cells": [
        {
            "source": "# SETI CNN using TF and Binary DS", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "[sudo] password for sd22-2e55b7df66e8c3-b01c69100280: \n\n", 
                    "output_type": "stream"
                }
            ], 
            "source": "import requests\nimport json\n#import ibmseti\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nimport pickle\nimport time\n!sudo pip install sklearn\nimport os\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics", 
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "### import dataset reader", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "--2017-05-24 18:46:43--  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\nResolving ibm.box.com (ibm.box.com)... 107.152.25.197, 107.152.24.197\nConnecting to ibm.box.com (ibm.box.com)|107.152.25.197|:443... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://ibm.ent.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip [following]\n--2017-05-24 18:46:43--  https://ibm.ent.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\nResolving ibm.ent.box.com (ibm.ent.box.com)... 107.152.25.211, 107.152.24.211\nConnecting to ibm.ent.box.com (ibm.ent.box.com)|107.152.25.211|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://public.boxcloud.com/d/1/s2_lVJepkZnrb_1Shd6kaEgHAevGs0Pd5Pr4PxpSpWc1x1Bn03Y-XRIHdHRDC3cFDI6wolqW4T4AyLiTRP6bYTFxXRMVMEHTfqHUVhpweNblBnDmW7o1cX-Su0YHKR5c0jUKxAUIA9_xo76GdqzUEvCJ7B8A1JeuNRYKl8pkPr2xFveYYwaiTKu5eboE2-PyrAhccwzBbasH7F6CCUWZUznvJnjyit0vxLoY-9mPtoRMCsfcmPBG3qbSbE12oBz9sCkyZuGZQkOhpP1sFkm4AWsHCK1OO35-1ARhquUV_vozJph4uHZagCis4Llag_BkbuzlX4kn2X9b7cGX3dU97qZCVMJO2-LsrwGqtSUK2WZXFV_yAyGbbgekEZNHUnUo7wYIlNcWAd2sbwEPa02gsZTge_Sc7l9muq2U4Xvj58ed9tL1jOafK7uBYiigyEErxMUJeJsrs72RS0NafEdf4XZp5wT76S2-PwiBbwh7hdDmRdFPpvizHz0OwlJl7-B-kw6X-A6mzNEdDiyzMBZ3DkZrzId8YTzVS7LIyfNBLsLhHa6FR12aflR07ou7mnzKkK6wpfOxcplZoxfiwb9wQmPonubY5J3b6josq_ozqoco6jn2759gT1VcGb9pFL9KLIJtAOvCP3_kPDEjdRCcpQsDtNlF6L9dyyq-9lDt3ayxIm4ehz4nM_x0TLmeBapta7YeEZgWLukuBQywgtpneG_bL0JN0ZnoAc2SrPbmdHLaPGT4nxAoJwCdiUHzd3x7LvqZku8pMfQ2Qf-BsGNuKRJ709Gf5_iiqeZ5CNbqY-ToVtdjhEgKzQIaPKERPPazCFzVOCo5ehhKvUf2CsIKFL68rrVT7JSFnnlPljawJ8Eyj7bYfnMGucQjo0TD7DQj_CsTI2AVX0t4t9AE5iqikHjk-CqFNNamGhKatDTnvDUI69A52sd1cmiNbECSe-nzoBVYG6DomAwj34u85oV7z5nkmXOL0-gNohyUyGU_Throjtujl_kMefOVgKioUB_UHfv552yRWPZL7ysuH1RzxAee0meEFXHs6SttXTDyLIazPwxgZ5h-_Ygcy90tCKomEc_gxRP9cjg-i8uppZaPmmnI69UQVEfWQ7j1f4V8GNUE-vBpzt_DesAkUZjmey621qDo_0RKH0blzZuhZbOOJQ../download [following]\n--2017-05-24 18:46:43--  https://public.boxcloud.com/d/1/s2_lVJepkZnrb_1Shd6kaEgHAevGs0Pd5Pr4PxpSpWc1x1Bn03Y-XRIHdHRDC3cFDI6wolqW4T4AyLiTRP6bYTFxXRMVMEHTfqHUVhpweNblBnDmW7o1cX-Su0YHKR5c0jUKxAUIA9_xo76GdqzUEvCJ7B8A1JeuNRYKl8pkPr2xFveYYwaiTKu5eboE2-PyrAhccwzBbasH7F6CCUWZUznvJnjyit0vxLoY-9mPtoRMCsfcmPBG3qbSbE12oBz9sCkyZuGZQkOhpP1sFkm4AWsHCK1OO35-1ARhquUV_vozJph4uHZagCis4Llag_BkbuzlX4kn2X9b7cGX3dU97qZCVMJO2-LsrwGqtSUK2WZXFV_yAyGbbgekEZNHUnUo7wYIlNcWAd2sbwEPa02gsZTge_Sc7l9muq2U4Xvj58ed9tL1jOafK7uBYiigyEErxMUJeJsrs72RS0NafEdf4XZp5wT76S2-PwiBbwh7hdDmRdFPpvizHz0OwlJl7-B-kw6X-A6mzNEdDiyzMBZ3DkZrzId8YTzVS7LIyfNBLsLhHa6FR12aflR07ou7mnzKkK6wpfOxcplZoxfiwb9wQmPonubY5J3b6josq_ozqoco6jn2759gT1VcGb9pFL9KLIJtAOvCP3_kPDEjdRCcpQsDtNlF6L9dyyq-9lDt3ayxIm4ehz4nM_x0TLmeBapta7YeEZgWLukuBQywgtpneG_bL0JN0ZnoAc2SrPbmdHLaPGT4nxAoJwCdiUHzd3x7LvqZku8pMfQ2Qf-BsGNuKRJ709Gf5_iiqeZ5CNbqY-ToVtdjhEgKzQIaPKERPPazCFzVOCo5ehhKvUf2CsIKFL68rrVT7JSFnnlPljawJ8Eyj7bYfnMGucQjo0TD7DQj_CsTI2AVX0t4t9AE5iqikHjk-CqFNNamGhKatDTnvDUI69A52sd1cmiNbECSe-nzoBVYG6DomAwj34u85oV7z5nkmXOL0-gNohyUyGU_Throjtujl_kMefOVgKioUB_UHfv552yRWPZL7ysuH1RzxAee0meEFXHs6SttXTDyLIazPwxgZ5h-_Ygcy90tCKomEc_gxRP9cjg-i8uppZaPmmnI69UQVEfWQ7j1f4V8GNUE-vBpzt_DesAkUZjmey621qDo_0RKH0blzZuhZbOOJQ../download\nResolving public.boxcloud.com (public.boxcloud.com)... 107.152.25.200, 107.152.24.200\nConnecting to public.boxcloud.com (public.boxcloud.com)|107.152.25.200|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3288 (3.2K) [application/zip]\nSaving to: \u2018SETI.zip\u2019\n\n100%[======================================>] 3,288       --.-K/s   in 0s      \n\n2017-05-24 18:46:44 (178 MB/s) - \u2018SETI.zip\u2019 saved [3288/3288]\n\nArchive:  SETI.zip\n  inflating: SETI.py                 \n  inflating: __MACOSX/._SETI.py      \n", 
                    "output_type": "stream"
                }
            ], 
            "source": "!wget --output-document SETI.zip  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n!unzip -o SETI.zip\nimport SETI", 
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "### Download data", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [], 
            "source": "ds_directory = 'SETI/SETI_ds_64x128/'\nds_name = 'SETI/SETI64x128.tar.gz'", 
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "# @hidden_cell\n!rm -r SETI/*\n!mkdir SETI\nos.system('wget --output-document '+ ds_name +' https://ibm.box.com/shared/static/zl3e3y7780h3bsqwt1g5elg57jvw7a3z.gz')\nos.system('tar -xvf '+ ds_name)", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "raw"
        }, 
        {
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "total 7152\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users 1665328 May 22 21:11 train-images-idx3-ubyte.gz\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users     306 May 22 21:11 train-labels-idx1-ubyte.gz\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users  765379 May 22 21:11 test-images-idx3-ubyte.gz\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users     172 May 22 21:11 test-labels-idx1-ubyte.gz\n\n", 
                    "output_type": "stream"
                }
            ], 
            "source": "print os.popen(\"ls -lrt \"+ ds_directory).read() # to verify", 
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "### Load data SETI", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "Extracting SETI/SETI_ds_64x128/train-images-idx3-ubyte.gz\nExtracting SETI/SETI_ds_64x128/train-labels-idx1-ubyte.gz\nExtracting SETI/SETI_ds_64x128/test-images-idx3-ubyte.gz\nExtracting SETI/SETI_ds_64x128/test-labels-idx1-ubyte.gz\n", 
                    "output_type": "stream"
                }, 
                {
                    "output_type": "execute_result", 
                    "execution_count": 5, 
                    "data": {
                        "text/plain": "(694, 8192)"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "#from tensorflow.examples.tutorials.mnist import input_data\n#dataset = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\ndataset = SETI.read_data_sets(ds_directory, one_hot=True, validation_size=0)\ndataset.train.images.shape", 
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "## Network Parameters", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [], 
            "source": "# Parameters\ndecay_rate=0.98\ndecay_steps=1000\nlearning_rate = 0.05\ntraining_epochs = 20\nbatch_size = 50\ndisplay_step = 100\n\n#check point directory\nchk_directory = 'SETI/save/'\ncheckpoint_path = chk_directory+'model.ckpt'\n\n\nn_classes = 4 # number of possible classifications for the problem\ndropout = 0.50 # Dropout, probability to keep units\n\nheight = 64 # height of the image in pixels \nwidth = 128 # width of the image in pixels \nn_input = width * height # number of pixels in one image \n", 
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "### Inputs", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [], 
            "source": "x  = tf.placeholder(tf.float32, shape=[None, n_input])\ny_ = tf.placeholder(tf.float32, shape=[None, n_classes])", 
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 8, 
                    "data": {
                        "text/plain": "<tf.Tensor 'Reshape:0' shape=(?, 64, 128, 1) dtype=float32>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "x_image = tf.reshape(x, [-1,height,width,1]) \nx_image", 
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "#### Convolutional Layer 1", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 9, 
                    "data": {
                        "text/plain": "<tf.Tensor 'MaxPool:0' shape=(?, 32, 64, 32) dtype=float32>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1))\nb_conv1 = tf.Variable(tf.constant(0.1, shape=[32])) # need 32 biases for 32 outputs\nconvolve1 = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1\nh_conv1 = tf.nn.relu(convolve1)\nconv1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\nconv1", 
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "#### Convolutional Layer 2", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 10, 
                    "data": {
                        "text/plain": "<tf.Tensor 'MaxPool_1:0' shape=(?, 8, 16, 64) dtype=float32>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))\nb_conv2 = tf.Variable(tf.constant(0.1, shape=[64])) #need 64 biases for 64 outputs\nconvolve2= tf.nn.conv2d(conv1, W_conv2, strides=[1, 1, 1, 1], padding='SAME')+ b_conv2\nh_conv2 = tf.nn.relu(convolve2)\nconv2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 4, 4, 1], padding='SAME') #max_pool_2x2\nconv2", 
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "#### Convolutional Layer 3", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "source": "W_conv3 = tf.Variable(tf.truncated_normal([5, 5, 64, 128], stddev=0.1))\nb_conv3 = tf.Variable(tf.constant(0.1, shape=[128])) #need 64 biases for 64 outputs\nconvolve3= tf.nn.conv2d(conv2, W_conv3, strides=[1, 1, 1, 1], padding='SAME')+ b_conv3\nh_conv3 = tf.nn.relu(convolve3)\nconv3 = tf.nn.max_pool(h_conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\nconv3", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "raw"
        }, 
        {
            "source": "#### Convolutional Layer 4", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "source": "W_conv4 = tf.Variable(tf.truncated_normal([5, 5, 128, 256], stddev=0.1))\nb_conv4 = tf.Variable(tf.constant(0.1, shape=[256])) #need 64 biases for 64 outputs\nconvolve4= tf.nn.conv2d(conv3, W_conv4, strides=[1, 1, 1, 1], padding='SAME')+ b_conv4\nh_conv4 = tf.nn.relu(convolve4)\nconv4 = tf.nn.max_pool(h_conv4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "raw"
        }, 
        {
            "source": "#### Fully Connected Layer 1", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 11, 
                    "data": {
                        "text/plain": "[None, 8, 16, 64]"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "input_layer = conv2\ndim = input_layer.get_shape().as_list()\ndim", 
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 12, 
                    "data": {
                        "text/plain": "<tf.Tensor 'Relu_2:0' shape=(?, 1024) dtype=float32>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "dims= dim[1]*dim[2]*dim[3]\nnodes1 = 1024\nprv_layer_matrix = tf.reshape(input_layer, [-1, dims])\nW_fc1 = tf.Variable(tf.truncated_normal([dims, nodes1], stddev=0.1))\nb_fc1 = tf.Variable(tf.constant(0.1, shape=[nodes1])) # need 1024 biases for 1024 outputs\nh_fcl1  = tf.matmul(prv_layer_matrix, W_fc1) + b_fc1\nfc_layer1 = tf.nn.relu(h_fcl1) # ???\nfc_layer1\n", 
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "#### Droupout 1", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [], 
            "source": "keep_prob = tf.placeholder(tf.float32)\nlayer_drop1 = tf.nn.dropout(fc_layer1, keep_prob)", 
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "#### Fully Connected Layer 2", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "source": "nodes2 = 256\nW_fc2 = tf.Variable(tf.truncated_normal([layer_drop1.get_shape().as_list()[1], nodes2], stddev=0.1))\nb_fc2 = tf.Variable(tf.constant(0.1, shape=[nodes2])) \nh_fcl2  = tf.matmul(layer_drop1, W_fc2) + b_fc2\nfc_layer2 = tf.nn.relu(h_fcl2) # ???\nfc_layer2", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "raw"
        }, 
        {
            "source": "#### Droupout 2", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "source": "layer_drop2 = tf.nn.dropout(fc_layer2, keep_prob)", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "raw"
        }, 
        {
            "source": "#### Readout Layer", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [], 
            "source": "W_fc = tf.Variable(tf.truncated_normal([nodes1, n_classes], stddev=0.1)) #1024 neurons\nb_fc = tf.Variable(tf.constant(0.1, shape=[n_classes])) # 10 possibilities for classes [0,1,2,3]\nfc = tf.matmul(layer_drop1, W_fc) + b_fc\ny_CNN= tf.nn.softmax(fc)", 
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "#### Loss function", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [], 
            "source": "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_l4_conv), reduction_indices=[1]))\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_CNN, labels=y_))", 
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "#### Training\n", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [], 
            "source": "# Create a variable to track the global step.\nglobal_step = tf.Variable(0, trainable=False)\n\n# create learning_decay\nlr = tf.train.exponential_decay( learning_rate,\n                                 global_step,\n                                 decay_steps,\n                                 decay_rate, staircase=True )", 
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "outputs": [], 
            "source": "# Use the optimizer to apply the gradients that minimize the loss\n# (and also increment the global step counter) as a single training step.\noptimizer = tf.train.GradientDescentOptimizer(lr)\n\ntrain_op = optimizer.minimize(cross_entropy, global_step=global_step)\n#train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)", 
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "#### Evaluation", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [], 
            "source": "correct_prediction = tf.equal(tf.argmax(y_CNN,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))", 
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "### Create checkpoint directory", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "model_checkpoint_path: \"SETI/save/model.ckpt-240\"\nall_model_checkpoint_paths: \"SETI/save/model.ckpt-240\"\n\n", 
                    "output_type": "stream"
                }
            ], 
            "source": "directory = os.path.dirname(chk_directory)\ntry:\n    os.stat(directory)\n    ckpt = tf.train.get_checkpoint_state(chk_directory)\n    print ckpt\nexcept:\n    os.mkdir(directory) ", 
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "## Training", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [], 
            "source": "# Initializing the variables\ninit = tf.initialize_all_variables()", 
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "loading model:  SETI/save/model.ckpt-240\nEpoch: 0001 lr= 0.050000001 cost= 1.172027258 Acc= 0.527692309\nEpoch: 0002 lr= 0.050000001 cost= 1.185723607 Acc= 0.504615380\nEpoch: 0003 lr= 0.050000001 cost= 1.169946863 Acc= 0.523076917\nEpoch: 0004 lr= 0.050000001 cost= 1.155229550 Acc= 0.563076920\nEpoch: 0005 lr= 0.050000001 cost= 1.171567935 Acc= 0.526153844\nEpoch: 0006 lr= 0.050000001 cost= 1.177281050 Acc= 0.512307690\nEpoch: 0007 lr= 0.050000001 cost= 1.159419537 Acc= 0.553846148\nEpoch: 0008 lr= 0.050000001 cost= 1.155651138 Acc= 0.540000003\nEpoch: 0009 lr= 0.050000001 cost= 1.178517287 Acc= 0.524615382\nEpoch: 0010 lr= 0.050000001 cost= 1.163363163 Acc= 0.538461536\nEpoch: 0011 lr= 0.050000001 cost= 1.169976308 Acc= 0.547692313\nEpoch: 0012 lr= 0.050000001 cost= 1.170629538 Acc= 0.519999995\nEpoch: 0013 lr= 0.050000001 cost= 1.170866223 Acc= 0.530769231\nEpoch: 0014 lr= 0.050000001 cost= 1.171847884 Acc= 0.523076924\nEpoch: 0015 lr= 0.050000001 cost= 1.164373132 Acc= 0.552307693\nEpoch: 0016 lr= 0.050000001 cost= 1.163633640 Acc= 0.533846158\nEpoch: 0017 lr= 0.050000001 cost= 1.160224529 Acc= 0.544615381\nEpoch: 0018 lr= 0.050000001 cost= 1.177783654 Acc= 0.527692307\nEpoch: 0019 lr= 0.050000001 cost= 1.166353932 Acc= 0.564615387\nEpoch: 0020 lr= 0.050000001 cost= 1.166012957 Acc= 0.563076932\nOptimization Finished!\nmodel saved to SETI/save/model.ckpt\n", 
                    "output_type": "stream"
                }
            ], 
            "source": "loss_values = []\nwith tf.Session() as sess:\n\n    \n    X_test = dataset.test.images\n    y_test = dataset.test.labels\n    sess.run(init)\n    saver = tf.train.Saver(tf.all_variables())\n    \n    # load previously trained model if appilcable\n    ckpt = tf.train.get_checkpoint_state(chk_directory)\n    if ckpt:\n        print \"loading model: \",ckpt.model_checkpoint_path\n        saver.restore(sess, ckpt.model_checkpoint_path)\n    \n    \n    #step = 0\n    num_examples = dataset.train.num_examples\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_loss = 0.\n        avg_accuracy = 0.\n        #dataset.shuffle_data()\n        total_batch = int(num_examples / batch_size)\n\n        # Loop over all batches\n        for step in range(total_batch):\n            start = time.time()\n            x_batch, y_batch = dataset.train.next_batch(batch_size,shuffle=True)\n            train_op.run(feed_dict={x: x_batch, y_: y_batch, keep_prob: dropout})\n            loss, acc = sess.run([cross_entropy, accuracy], feed_dict={x: x_batch,y_: y_batch,keep_prob: 1.})\n            \n            \n            end = time.time()\n            \n            avg_loss += loss / total_batch\n            avg_accuracy += acc / total_batch\n            if step % display_step == 1000:\n\n                \n                # Calculate batch loss and accuracy\n                loss, acc = sess.run([cross_entropy, accuracy], feed_dict={x: x_batch,y_: y_batch,keep_prob: 1.})\n                #train_accuracy = accuracy.eval(feed_dict={x:x_batch, y_: y_batch,  keep_prob: 0.5})\n\n                test_accuracy = sess.run(accuracy, feed_dict={x: X_test[0:100], y_: y_test[0:100], keep_prob: 1.})\n\n                print(\"Iter \" + str(step) + \\\n                    \", Training time= \" + \"{:.5f}\".format(end - start) + \\\n                    \", Minibatch Loss= \" +  \"{:.6f}\".format(loss) +  \\\n                    \", Training Accuracy= \" + \"{:.5f}\".format(acc)  + \\\n                    \", Test Accuracy= \" + \"{:.5f}\".format(test_accuracy) )\n        \n        # save model every 1 epochs\n        if epoch >= 0 and epoch % 1 == 0:\n            # Save model\n            #print (\"model saved to {}\".format(checkpoint_path))\n            #saver.save(sess, checkpoint_path, global_step = epoch)\n            plr = sess.run(lr)\n            loss_values.append(avg_loss)\n            #print(sess.run(tf.train.global_step()))\n            print \"Epoch:\", '%04d' % (epoch+1), \"lr=\", \"{:.9f}\".format(plr), \"cost=\", \"{:.9f}\".format(avg_loss) ,\"Acc=\", \"{:.9f}\".format(avg_accuracy)\n\n    print(\"Optimization Finished!\")\n    print (\"model saved to {}\".format(checkpoint_path))\n    saver.save(sess, checkpoint_path, global_step = (epoch+1)*step)\n\n    \n    \n    # Calculate accuracy for test images\n    #print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: X_test[0:30], y_: y_test[0:30], keep_prob: 1.}))\n        \n    # Find the labels of test set\n    y_pred_lb = sess.run(tf.argmax(y_CNN,1), feed_dict={x: X_test[0:100], y_: y_test[0:100], keep_prob: 1.})\n    y_pred = sess.run(y_CNN, feed_dict={x: X_test[0:100], y_: y_test[0:100], keep_prob: 1.})\n    \n    # lets save kernels\n    kernels_l1 = sess.run(tf.reshape(tf.transpose(W_conv1, perm=[2, 3, 0, 1]),[32,-1]))\n    kernels_l2 = sess.run(tf.reshape(tf.transpose(W_conv2, perm=[2, 3, 0, 1]),[32*64,-1]))", 
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "outputs": [
                {
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<matplotlib.figure.Figure at 0x7f4b3dbaf550>", 
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEGCAYAAACHGfl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYVOWV+PHvAQRFEEXiBjSgoAKaiFHckw46LIaISzQY\nMzEzqFFwTaKASRQS40J0NI5DVsafSVR0SFQwKri1cWkWBdxopFGBblrQIOCOLOf3x7klZVndVdV1\nq+6tqvN5nn6ovvXee99quuvUu51XVBXnnHOVrU3UFXDOORc9DwbOOec8GDjnnPNg4JxzDg8Gzjnn\n8GDgnHOOMggGIvJtEXlFRLaKyKEtlJsmImtF5KU0z10kIktF5GURuT44driILEr6OrmQr8M556JU\nUsFARL4uIrenHH4ZOAV4KsPptwPD0lyzGvgWcJCqHgzcmHTdr6rqIGAE8HsRKamfl3POZatd1BVo\nhc+tklPV1wBERFo8SfUZEemV5qkLgOtVdUtQ7l/Bv58kldkJ2JZPpZ1zLs5K8ZNui2/6rbA/8DUR\nmSsiT4rIYZ/dSGSwiLwCvAicr6oeEJxzZakkWgYiMhdoD3QGdhORhcFT41X10Twv3w7YVVWPFJHD\ngXuBfQFUdT5wkIgcAPxZRB5W1U/zvJ9zzsVOSQQDVT0SbMwAOFtV/zPEyzcAfw/us0BEtonI7qq6\nLun+r4nIh8BBwMJmruOccyUrq24iERkezLZZJiLj0zzfXkSmi0i9iNSKSFXScxOD43UiMjTp+CXB\n7J2XReTicF5Oxi4kSVPmfuD4oE77Azuo6joR6S0ibYPjvbDupBUh1dM552IlYzAIZtDchs3EGQic\nKSIHphQbA7yrqv2AW4ApwbkDgDOA/tiMnKliBgbnHAYcAnxLRPZrzQsQkZNFpAE4EnhQRB4Oju8t\nIg8mlbsLeA7YX0RWich/BE/dDuwrIi8DdwHfD44fC7wYdEn9DbhAVd9tTR2dcy7uJFMKaxE5Erha\nVUcE308AVFVvSCrzSFBmXvBp+i1V3SO1bPBGPQnoCQxV1fOC4z8DPlHVG3HOOVd02XQTdcf61RMa\ng2Npy6jqVmCjiHRNc+7q4Ngr2Aye3USkI3AiFiCcc85FIJsB5HT98KnNiebKpD2uqktF5AbgMeB9\nYDGwJYu6OOecK4BsgkEjUJX0fQ+gKaVMA/bJvinoJuqiqutFpJHPf+L/7FxVvR3rr0dEfsXnWxCf\nERHfis0553Kkqjmtycqmm2gB0FdEeolIe2A0MDOlzCzg7ODx6cATweOZwOhgtlEfoC8wH0BEvhT8\nW4Wlk7i7uQqoas5f27YpJ56o7Lln7ueW69fVV18deR3K6ct/nv7zjOtXa2RsGajqVhG5EJiDBY9p\nqlonIpOBBar6IDAN+IuI1APrsICBqi4RkXuBJcBmYKxur+nfgnGFxPGNrXoFzbjnHli1CjZsgI8/\nhp12CvPqzjlXXrJadKaqjwAHpBy7OunxJmwKabpzrwOuS3P8aznVNAfr1sFll8EDD8BZZ8GKFdC/\nf6Hu5pxzpa8UcxNl9KMfwejRMHgw9OkDb74ZdY3iobq6OuoqlBX/eYbLf57RyrjOIGoiornUcfZs\nOP98ePll6NQJfvhD+PKXYdy4AlbSOediRETQAgwgl4wPPrBA8LvfWSAAbxk451w2yioY/PzncNxx\nMCxpCxsPBs45l1lJZC3Nxrx5cPfd8Oqrnz/ep48NIDvnnGteWbQMPv0UzjkHbr4Zdt/98895y8A5\n5zIri2AwZQr06mUziFJ16wabNsHGUFcxOOdceSn5bqK6OrjlFli4ENLtgiyyvXVwyCHFr59zzpWC\nkm4ZbNsG554LkyZBVVXz5byryDnnWlbSweD3v7eAMHZsy+U8GDjnXMtKtpuosRGuugqeegraZAhp\nHgycc65lJdkyUIULLoCLLoIBAzKX92DgnHMtK8mWwb332pv73/6WXXkPBs4517KSy020bh0cdBDc\ndx8ceWR219i4EfbZx9JVpJtx5Jxz5aQichP9+MdwxhnZBwKALl2gQwd4553C1cs550pZSXUTPfoo\n1NTAK6/kfm6iq2iPPUKvlnPOlbysWgYiMlxElorIMhEZn+b59iIyXUTqRaQ22Moy8dzE4HidiAxN\nOn6ZiLwiIi+JyJ3BlprN+vBDS0f9299uz0iaCx83cM655mUMBiLSBrgNGAYMBM4UkQNTio0B3lXV\nfsAtwJTg3AHYDmj9gRHAVDH7ABcBh6rql7EWSppkEttddRUcfTSMGJHLy9vOE9Y551zzsmkZDAbq\nVXWlqm4GpgOjUsqMAu4IHs8AhgSPTwKmq+oWVV0B1AfXA2gL7Cwi7YCOQFNzFViwAO6809JOtJa3\nDJxzrnnZBIPuQEPS943BsbRlVHUrsDHY7D713NVAd1VtAm4CVgXHNqjqY81VYMwYuOkmSzrXWr17\nezBwzrnmZDOAnG56Uup81ObKpD0uIrtirYlewEZghoh8V1XvSleBjz+exLJlloOourq6VXulesvA\nOVeuampqqKmpyesa2QSDRiA5DVwPvtil0wD0BJpEpC3QRVXXi0hjcDz13BOAN1T1XQAR+TtwNJA2\nGDz22CR69cqipi3o3RtWrYKtW6Ft2/yu5ZxzcZL6IXny5Mk5XyObbqIFQF8R6RXM+BkNzEwpMws4\nO3h8OvBE8HgmMDqYbdQH6AvMx7qHjhSRHUVEgOOBuuYqkG8gANhpJ+jaFZqaHZlwzrnKlbFloKpb\nReRCYA4WPKapap2ITAYWqOqDwDTgLyJSD6wjmBmkqktE5F5gCbAZGBssJ54vIjOARcHxRcAfwn95\nn5eYUdSzZ8aizjlXUUouHUU+zjoLhg2D738/lMs551wsVUQ6inz4ILJzzqVXUcHAp5c651x6FRUM\nvGXgnHPpeTBwJeWTT+DrX7dU5s658FRUMOjZE9asgU8/jbomrrUWLoR//tNWpDvnwlNRwWCHHWyT\nm4aGzGVdPM2dC9/6Fvz+974/hXNhqqhgAN5VVOpqa+E737GvG2+MujbOlQ8PBq6k1NbaLndXXgl/\n/CO8/XbUNXKuPFRcMPDppaWrocHGe/bdF3r0sEWEU6ZEXSvnykPFBQNvGZSu2lo46iiQYF3lxInw\nv/9rkwKcc/nxYOBKxty5FgwS9tnHUovccEN0dXKuXFRkMPDtL0tTomWQbPx4uOMOz0brXL4qKlEd\nwLZtsPPOtmipY8fQLusKbNMmS0H+9tv2/5fsxz+GzZvh1lujqZtzceOJ6rLQpg1UVXnroNQsXAgH\nHPDFQABwxRXw179CY2Px6+Vcuai4YAA+o6gUpesiSthzTzjnHLjuuuLWyblyUpHBwAeRS0/q4HGq\nyy+H6dNta1PnXO6yCgYiMlxElorIMhEZn+b59iIyXUTqRaRWRKqSnpsYHK8TkaHBsf1FZJGILAz+\n3SgiF4f3slrmwaD0tNQyAPjSl+C88+BXvypenZwrJxmDgYi0AW4DhgEDgTNF5MCUYmOAd1W1H3AL\nMCU4dwBwBtAfGAFMFRsRXqaqg1T1UOCrwIfAfSG9pox8RlFpaWy0bKX77ttyuZ/8BGbM8P9b51oj\nm5bBYKBeVVeq6mZgOjAqpcwo4I7g8QxgSPD4JGC6qm5R1RVAfXC9ZCcAr6tq0dLHecugtKQuNmvO\n7rvDBRfANdcUp16uvKxYAbNnR12L6GQTDLoDyW/UjcGxtGVUdSuwUUS6pjl3dZpzvwPcnUOd8+bB\noLRk6iJK9qMfwf33w+uvF7ZOrvz86U+V3c3YLosy6T6PpU78b65Mi+eKyA5Y62FCSxWYNGnSZ4+r\nq6uprq5uqXhGu+8OW7bAhg2w6655XcoVwdy5cO212ZXt2hXGjbPWwe23F7ZerrzMng3Ll4Nq5lZo\n3NTU1FBTU5PXNTIuOhORI4FJqjo8+H4CoKp6Q1KZh4My80SkLfCWqu6RWlZEHgGuVtV5wfcnAWMT\n127m/qEuOks4+GD4859h0KDQL+1ClFhstnYtdOqU3TkbNkDfvtai6NevsPVz5eFf/7IxqQ4dYPFi\n6J7af1FiCrXobAHQV0R6iUh7YDQwM6XMLODs4PHpwBPB45nA6GC2UR+gLzA/6bwzKXIXUYJ3FZWG\nRYtg//2zDwRgrb2LL4Zf/rJw9XLl5fHHbTvVr3wFXn456tpEI2MwCMYALgTmAK9iA8J1IjJZREYG\nxaYB3USkHriUoNtHVZcA9wJLgIewVoACiMhO2ODx38N9SdnxGUWlIZfxgmSXXAIPPwyvvRZ+nVz5\nmT0bhg6Fgw6q3GBQcbmJEm65xQYZ//u/Q7+0C9EZZ9g2l//+77mfe+218OqrcOed4dfLlQ9V2x/9\niSfg6adtj+077sh8Xpx5bqIceDdRaci08rglF10Ejz4KdXXh1smVl7o6aNfOxpcOPrhyWwYeDFxs\nrV4NH38M++3XuvM7d7aMppMnh1svV14SXUQiMGAALF1qsw0rTcUGg969bcwg5r1kFS2x33E+0/zG\njYMnn4RXXgmvXq68zJkDw4bZ406dYO+9K3OdSsUGg112gR139A3V46y1g8fJOnWyJHbeOnDpfPIJ\nPPMMDBmy/VildhVVbDAA7yqKuzCCAViKimeegRdfzP9arrw884zNINptt+3HKnVGUcUHA59eGk+b\nNtmb9+GH53+tnXe2DXC8deBSJXcRJXjLoAJ5yyC+Fi+22R25LDZryfnn28ykRYvyu87y5XDzzXDC\nCfDb34ZTNxedOXNs8DjZwQdX5hiTBwMPBrEUVhdRwk47wYQJkJTmKitbtti888svhwMPhOOOgyVL\nYPRouOoqWL8+vDq64lqzBlauhMEpeZT79YOGBvjoo2jqFRUPBh4MYinsYAC2+c0LL8Dzz7dcbv16\nuPtuOOss21Lzssusq+mvf7Xprn/8o22zefLJcMMNLV/Lxdejj9rAcbuUdJ077GApUJYsiaZeUano\nYOB7IcdXIYLBjjvCxInpWwfLlsFNN8E3vgG9esFdd1mumpdesgAyaRIcdhi0SfqLufpqCwyrV4db\nT1cc6bqIEiqxq6hi01GATSvr0sWag23bFuQWrhVWr7aEYe+8E34q4U2brBvg7rth82aYNQsefBA+\n+ABGjrTUF0OGQMeO2V3viivgvffgd78Lt56usLZts/UEc+daD0Gq66+337+bbip+3cLQmnQU2exn\nULZ23NH2NmhqstwkLh7mzs1/sVlzOnSAn/7U+v6/+lV787/7bktl3pr7TZhgXQo//rGnyy4lL71k\nHwTTBQKwlsFvflPcOkWtooMBbB838GAQH4XoIkp23nnw7W/bB4F8de1qu6v97Gdwzz35X88VR0td\nRFCZ3UQVPWYAPogcR4UOBiLhBIKESy6xbJcvvBDeNV1hzZ79xfUFyXr2hA8/hHXrilenqHkw8GAQ\nK59+amsMwlhsViw77ww//zlceWXUNXHZ+PBDmDcPWto9V6TyViJ7MPBgECuLF9uWlZ07R12T3Jxz\njiU3e+KJzGVdtJ56ysaLMv2OVVpXUVbBQESGi8hSEVkmIuPTPN9eRKaLSL2I1IpIVdJzE4PjdSIy\nNOl4FxH5v+D4qyJyRDgvKTc+vTReCt1FVCg77GDbbE6c6Jlw4y5dCop0Ki0tRcZgICJtgNuAYcBA\n4EwROTCl2BjgXVXtB9wCTAnOHQCcAfQHRgBTRT6bs/Eb4CFV7Q98BYhkCxLPTxQvpRoMAL7zHevm\nuu++qGviWpJp8DjBu4m+aDBQr6orVXUzMB0YlVJmFJDYKG4GkEgIexK2Z/IWVV0B1AODRaQzcJyq\n3g4QPP9efi+ldXr2hLVr7Y/YRa+Ug0GbNnDddTZ1tRI3RykFDQ2Wtn7QoMxlE91EldLSyyYYdAca\nkr5vDI6lLaOqW4GNItI1zbmrg2P7Av8SkdtFZKGI/EFEdmrla8hLu3awzz6walUUd3fJmpps8Vcp\nz9cfNsxSWPz5z1HXxKUzZw78279lt8i0a1cbV6iU94Zs1hmkW4qTGiubK9Pc8XbAocA4VX1eRG4B\nJgBXp6vApKT8AdXV1VS3NA2gFRKDyH37hnpZl6NCLjYrFhFrHXznO/Dd79rCRhcfc+bA8OHZl090\nFfXqVbg6haGmpoaampq8rpFNMGgEqpK+7wE0pZRpAHoCTSLSFuiiqutFpDE4nnpuI9CgqomUYTOA\nLwxMJ0zKNdVkjnxGUTyUchdRsqOOgkMPhalTbUGai4etW+Gxx3JLMZEYRB45snD1CkPqh+TJrdi8\nI5tuogVAXxHpJSLtgdHAzJQys4Czg8enA4kJdjOB0cFsoz5AX2C+qq4FGkRk/6Dc8UBkOQJ9RlE8\nlEswAPjVryyj6caNUdfEJbzwguUj6tEj+3MqaXppxmAQjAFcCMwBXsUGhOtEZLKIJOLlNKCbiNQD\nl2JdPqjqEuBe7I3+IWBsUta5i4E7RWQxNpvo2vBeVm68ZRC9xGKz1NzypWrgQDjxRLjxxqhr4hKy\nnUWUrJJmFFV01tKEZ5+1RGNz5xb0Nq4F8+fDueeW1z7FK1dad9GSJTao7KJ13HE20yuXMYOPP7aB\n5Pfes7UkpaI1WUsrfgUyeMsgDhKDx+WkVy/4/vfhmmuirol77z1reX7ta7mdt9NOUFVl+12UOw8G\nwF572S/Lhx9GXZPKVU7jBcmuvNJSZL/xRtQ1qWxPPmkfNrLdpyJZpXQVeTDAFgv16uUrkaNUrsHg\nS1+Ciy+2/ZJddGbPzn28IKFS0lJ4MAh4V1F03noL3n/fNokpR5ddZlMay2k8pNRkm48onUqZUeTB\nIODTS6Mzdy4ccURpLzZrSefO1l30059GXZPK9PrrtrL94INbd753E1UYT1gXnXLtIkr2wx/ap8un\nn466JpUnMaW0tR82+vaFNWus9VrOPBgEvJsoOpUQDDp0gF/8wlNcRyGfLiKwPEb9+9sU4XLmwSAQ\n52CgCv/+79bULTeffgqLFpXPYrOWnHWWrUh+8MGoa1I5Nm+2mUQnnJDfdSphENmDQSDOweDtt+Gv\nf4W77oq6JuF78UXYd1/YZZeoa1J4bdvCtdfa+MHWrVHXpjLMm2d/2/ku+quEcQMPBoGuXWHbNli/\nPuqafFF9vc2P/u1vy6+LoRwXm7Vk5EgLfOUY2OMo3y6ihEqYUeTBICAS39ZBfT2ccop1E82bF3Vt\nwlUJ4wXJROD6623dwaZNUdem/LUmH1E63k1UYXr3jueMovp6m4N//vmWFrmcVFowAMuRM3Ag/OEP\nUdekvL37rg36HnNM/tfae2/bvW7t2vyvFVceDJLEuWXQrx/84AcwaxasWxd1jcKxZo0NqJbrYrOW\nXHutpbku9+mKUXr8cQu8HTrkfy2R8m8deDBIEvdgsPvucNJJcPvtUdcoHLW1Nl7QpgJ/C7/8ZVto\n9/e/R12T8hVWF1FCuY8bVOCfYfPiGAxUYfny7fsCjx0Lv/udDXaXukobPE51+unwt79FXYvypJpf\nPqJ0yn1GUVbBQESGi8hSEVkmIl/YnjLYyWy6iNSLSK2IVCU9NzE4XiciQ5OOrxCRF0VkkYjMD+fl\n5CeOwaCpyWYSdeli3w8ebLNRHn002nqFoRLHC5KNHAk1Nd5VVAivvWb/HnhgeNes+G4iEWkD3AYM\nAwYCZ4pI6o94DPCuqvYDbgGmBOcOAM4A+gMjgKkiny0K3wZUq+ogVY3FkqPEAHKcpm8muogSROCC\nC2yaaSnbvBkWLrSukkq1665w7LHwj39EXZPyk2gVhJnv6qCDbEC6HFrl6WTTMhgM1KvqSlXdDEwH\nRqWUGQXcETyeAQwJHp+EbZO5RVVXAPXB9QAky/sXTefO9ik8TjMGUoMBwHe/azluVq2Kpk5hePFF\na4lVwmKzlpx2mncVFULY4wVgrfOuXePXexCWbN6MuwMNSd83BsfSlgn2TN4oIl3TnLs66VwFZovI\nAhE5txV1L4i4JaxLTCtNtvPOltrgj3+Mpk5hqPQuooRRo+yN66OPoq5J+di0yT4s5ZuCIp1y7irK\nJhika2ildqQ0V6alc49W1cOAE4FxInJsFnUpuLiNG6RrGYCtOfjTnyy3Tymq9MHjhG7d4LDDrFvD\nhePZZy2xXNeu4V+7nGcUtcuiTCNQlfR9D6AppUwD0BNoEpG2QBdVXS8ijcHxL5yrqmuCf98Rkfuw\n7qNn0lVg0qRJnz2urq6muro6i2q3TqkEgwED4IAD4P774Ywzil+vfNXWws9+FnUt4iHRVXTKKVHX\npDyElYIinYMOsrU+cVNTU0NNTU1+F1HVFr+AtsByoBfQHlgM9E8pMxaYGjwejY0TAAwAFgXn9Qmu\nI0BHoFNQZmfgWWBoM/fXYvrtb1XPOaeot2zW1q2qO+6o+v776Z+/5x7V6uri1ikMa9ao7rabvT6n\n2tSkuuuuqp98EnVNysOgQapPP12Yay9erNq/f2GuHabgfTPj+3vyV8ZuIrUxgAuBOcCrwRt9nYhM\nFpGRQbFpQDcRqQcuBSYE5y4B7gWWAA8BY4OK7gk8IyKLgLnALFWdk3MkK4A4tQwaG2G33aBTp/TP\nn3wyLF0KdXXFrVe+amttFlElLjZLZ++9LT3F449HXZPSt3YtvPFG4WapHXigvT+UY16pbLqJUNVH\ngANSjl2d9HgTNoU03bnXAdelHHsTOCTXyhZDnIJBc11ECe3bw5gxNs301luLV698JVYeu+0SXUUn\nnhh1TUrbY4/BN74BO+xQmOt36GAp15cuha98pTD3iIp/NktRVWWfyOOQbz5TMAA47zy480748MPi\n1CkMc+f6TKJUp54KM2daMjTXeoWYUpqqXFciezBIseOONsNj9eqoawLLlmUOBlVVtnDp7ruLU6d8\nbd4ML7xQ2YvN0unVyxY9PvVU1DUpXarFCQblOqPIg0EacekqyqZlALYieerUeK2cbs5LL9mbXiK9\nhtvOF6Dl5+WXbQ3OfvsV9j7lutbAg0EapRYMhg61VNDzY5HhqWW+2Kx5p50G991XvukOCq0YrQLw\nbqKKEodgsGWLrYTu2zdz2TZtbBFaKeQr8sHj5vXrB1/6Ejz3XNQ1KU1hZyltTp8+tnHOhg2Fv1cx\neTBIIw7BYNUq2GMP2Gmn7Mr/x3/YArQ4b3yzbRs88QQUcM1gyfv2t4vfVbR5c3HvVwjr1tnEhCFD\nMpfNV5s2NhX41VcLf69i8mCQRhzyE2XbRZTQrRt861vw//5fwaqUt+eft3UThe7TLWWnnWYb3hRr\n/OcPf7B0GKUcEDZtstXbY8cWL/FhOXYVeTBIo3fv6FsGuQYDiP/GNzNnWsByzRswwFqDzz9f+Ht9\n+qltvbl1K9xyS+HvVwiqNr16993huusylw9LOQ4iezBIo0cPePvtaFcZtiYYHHmkzaaI60rWWbM8\nGGQiUrxZRX/+8/b8VjfcACtXFv6eYbv2Wuuu+etfi7uivRynl3owSKNdO+jePdr9AloTDBIb30yd\nWpg65WPlSlu74TOJMksEg0J2FW3ZYp+kf/5zm6Rw8cVwySWFu18h3HOPdXPNmmUfgoop0U1UCtO5\ns+XBoBlRDyK3JhiA7XPw1FO2ijpOHnzQUi20bRt1TeJv0CB7sy5kN8Rdd0HPnnDccfb9+PGW4yqO\nGTnTqa2Fiy6yrse99y7+/ffc0z40NqXmby5hHgyaEWUw2LzZWiX77pv7uZ062U5ocdv4xruIslfo\nrqKtW22sIDmFeIcO1qK86KL4pzZ5801L33H77dHmByq3riIPBs2IMhi8+Sbss4/9gbbGBRdYMIjL\nDJH337cNRwqVY74cFTIYzJhhG78cf/znjx9/PBx9NPzyl4W5bxg2bIBvfhOuvNL+jVK5zSjyYNCM\n3r2jm16abqvLXAwcaP3ADzwQXp3y8eijNlZQ6fsd5+KII2D9enjttXCvu20bXHONjRWk2yz+v/4L\npk2L5xz6zZttI6cTTrAWTNTKbUaRB4NmRNkyaO14QbKxY+OzItm7iHLXpo11hYTdOnjgAWtxjhiR\n/vm99oJJk+z3J06Do6oWAHbYwQJWHHg3UYUo9WBw6qn26W7p0nDq1Fpbt8I//uHBoDXC7ipStS6g\nn/0sfasg4fzz4aOPbOppXNx8s6XpmD7dBm7jYMAAG3SPQ7r7MGQVDERkuIgsFZFlIjI+zfPtRWS6\niNSLSK2IVCU9NzE4XiciQ1POayMiC0VkZv4vJVx77QUffGBfxRZGMGjfHv7zP20RWpTmz7eZF717\nR1uPUnTccTYrLKwPJQ89ZLOUTjqp5XJt21qrcvz4eKQ3uf9+uOkmm5HWuXPUtdmuc2d7n1i+POqa\nhCNjMBCRNsBtwDBgIHCmiByYUmwM8K6q9gNuAaYE5w7AdkDrD4wApop87jPJJdiWmLEjYjnmoxg3\nCCMYAPzwh/CXv0Q7O8S7iFqvbVsYNcrSU+QruVWQzeKsww6D00+HiRPzv3c+XngBzj3XureqqjKX\nL7Zy6irKpmUwGKhX1ZWquhmYDoxKKTMKuCN4PANIpIs6CdszeYuqrgDqg+shIj2AE4E/5fUKCiiK\nrqJNm2zuchifpHv1stkh06fnf63W8mCQn7C6ih57zNKcn3Za9udcc4118dXW5n//1mhstGCYyJ8U\nR+U0iJxNMOgONCR93xgcS1tGVbcCG0Wka5pzVyedezNwORCjYarPiyJh3Rtv2CegsPZwveCC6AaS\nV6ywtB6DB0dz/3LwjW/YjKJ8FxH+8pfw05/mtuivSxe48UYbQyj2dpwffAAjR9qq6FNOKe69c1FO\n00uzCQbphppS38CbK5P2uIh8E3hbVRcHZVoYzopOFAnrwuoiShg2zPp9FywI75rZmjXLVx3nq317\ne1O8777WX+Opp6y1OXp07ueOHm17LNx6a+vvn6utW+HMM+Hww+EnPynefVujnFoG2YzLNwLJvXU9\ngNRF2A1AT6BJRNoCXVR1vYg0BsdTzx0FfEtERgA7AZ1F5M+q+v10FZg0adJnj6urq6kuUkL8Pn2K\nv9FINvse56JtW/tkN3Wqrdgsplmz7N4uP6edZtMpWzu3/pe/tL7/1szCEbHfnaOPtjn+PXq0rg65\n+MlP4OOdKfHeAAAU8ElEQVSP7b4tzXqKg/33h4YGq2+2e48UQk1NDTU1NfldRFVb/ALaAsuBXkB7\nYDHQP6XMWGBq8Hg0Nk4AMABYFJzXJ7iOpJz7dWBmC/fXqDz/vOpXvlLce553nuptt4V7zbffVu3S\nRXXdunCv25KNG1U7d1Z9//3i3bNcffyx/f+tXZv7uc89p1pVpbppU351uOoq1dNOy+8a2fif/1E9\n8EDV9esLf6+wHHywvVfESfC+mfH9PfkrYzeR2hjAhcAc4NXgjb5ORCaLyMig2DSgm4jUA5cCE4Jz\nlwD3YjOGHgLGBhUtCYkB5GLWOOxuIrBm/je/CXfckblsWObMsU+TnToV757lascdYfhwm2KZq2uu\ngQkTrLspHxMnwuLFNj21UB55xFox//gH7Lpr4e4TtnLpKpK4vzeLSGTxQ9V+Kd9803K5FEPPnvDP\nf1ogCtNzz8H3v2+DkcXowz/7bBs4Hjeu8PeqBP/3f/CnP9k+v9l64QWbjbN8uQWUfM2ebRMSXnkF\nOnbM/3rJXn7ZciPdf799iCgl118P//qXDbbHhYigqjl1svkK5BaIFHd66UcfwTvvFGY+9VFH2Z7K\nYcxZzySx6njkyMxlXXZGjLA9ftevz/6ca66Byy8PJxCATUY4/HDbUCYs771nb6bHHw+/+U3pBQIo\nnxlFHgwyKGbCutdft+BTiE/uInDFFbajVaEbWrW1NtDYq1dh71NJOnWyzd5nZrlW/6WXLHice264\n9bj5Zvj97/NPc7J+veVA2m8/a2nU1NgMolJULt1EHgwyKGbLoBDjBclOOsnmb+c76SATX2hWGLks\nQPvVr+BHPwq/O2effWwVc2sT2b3zjo0/9O1rs3Bqa23LygEDwq1nMVVV2d9VHFJ35MODQQYHHGDJ\nqIqh0MGgTRvrNpgypXD3AA8GhTJypAXy999vuVxdHTz5pPXvF8K4cfbJ/s47sz+nqcmC0wEH2Ero\nhQstVXbfvoWpYzGJWFdRqael8GCQwdFHwzPPFOdehQ4GAN/7Hrz4on0Vwuuv2xtFXNMHlLJdd4Vj\nj7XxmJZce62t3C3UTK527SwB4uWXZx7DWLnSgsdBB9n3r7xi6wfKrQuxHLqKPBhkMHCgpVR4++3C\n3yvsBWfpdOhgbxS//nVhrj9rlk1jzSYZmstdpq6i5cvh4YfhwgsLW48jjoCTT7YUF83VY8wYOPRQ\n29Ro6VJbOLfPPoWtV1TKIWGd/8lm0LZt8VoHxWgZgGUzffhh+9QWNu8iKqxRo2wNx0cfpX/+uuus\nP79Ll8LX5dprLU3G/Pnbjy1ZYq3Po46yadL19VanPfYofH2iVA4zijwYZOHYYwsfDN5/3/pSi7Hc\nf9dd7VNb2DtGbdxoOZBOOCHc67rtunWz6Z3p1husWGFvzpdeWpy67LabjT+df76taTj9dEusN3Cg\ndRdOmlS89TlRS7QMYr5sq0UeDLJw3HHw9NOFvcfy5TbNrljdK5dcYjtZhTkD4pFH7Ge1887hXdN9\nUXNdRTfcAOedV9w34O99zz5cjBxprYE33rDZQpW23/Xuu9vvfUND5rJx5cEgC4cdZjM0CrnrWbG6\niBK6d7fUwFOnhndN7yIqjlNOsbQQmzZtP7Z6Ndxzj83YKSYR24FsxQq7dyV/ECj1riIPBlnYcUcY\nNMgW8RRKsYMB2GyQ226zjIv52rLFxiF81XHh7bWXdcU8/vj2Y7/+NfzgB9H0zXfsaBMTKl2pzyjy\nYJClQo8bRBEM+veHI48MJ7X1c8/ZdMFijHm4z3cVrV1rXX6XXx5tnSqdB4MKUY7BACxFxU035b+T\nlXcRFdepp1pqii1b7P/vu9+FvfeOulaVrdSnl3owyNLRR8O8ebB5c2GuH1UwOOYY63bIN4GdB4Pi\nqqqyVCl//7tlM73iiqhr5Pr3t7VChXqPKDQPBlnabTf741u8OPxrb9hg88aj+mQ3frxNEWzttLj6\ness+eeih4dbLtey00+Ccc+zfQmS6dbnp2NHWVixbFnVNWseDQQ4KNcW0vt5ytES1xd/IkfDhh/DE\nE607P9Eq8FXHxXXaaTajaOLEqGviEg4+2Kb4Pv548wsD4yqrP18RGS4iS0VkmYiMT/N8exGZLiL1\nIlIrIlVJz00MjteJyNDgWAcRmScii0TkZRG5OryXVDiFGjeor7e9VKOSbwI77yKKRt++8NZbsO++\nUdfEJUyZYq2Dn//cZnZ97Wtw9dWWOPCTT6KuXcsy7nQmIm2AZcDx2Gb2C4DRqro0qcwFwMGqOlZE\nvgOcoqqjRWQAcCdwONADeAzop6oqIh1V9SMRaQs8C1ysqvNJEeVOZ6kaG60rZO3acD/FT54Mn35q\naYejsmmTvan84x9wyCHZn7d+ve35sGZNtBuCOxc3H3wAzz5rgaCmxgaXDz8cqqttpfYRRxRuSm6h\ndjobDNSr6kpV3QxMB0allBkFJHbYnQEMCR6fhO2ZvEVVVwD1wfVQ1UQjqgPQDojHO34LevSwfsGw\n+wSjGjxO1qGDpTHItXXw8MPw9a97IHAuVadOtjvc9dfbGqWmJmuBf/gh/PjHtmr5+ONtR7pnnrEP\nhFHKJhh0B5IXWTcGx9KWUdWtwEYR6Zrm3NWJc0WkjYgsAtYAj6rqgla9giIrRFdRHIIBWCqD2bNz\n28zHu4icy84uu8CJJ9oHrgULrKfhssusdX3xxRYchg61BIC5bG8alnZZlEnX1Ej9FN9cmWbPVdVt\nwCAR2QW4X0QGqOqSdBWYNGnSZ4+rq6uprq7OXOsCSQwijxkT3jXjEgy6dLHZKTffDLfemrn85s0W\nPMJOeOdcJUjkdEqs2l+/Hv75T+tWynUyRk1NDTV5bmGYzZjBkcAkVR0efD8BUFW9IanMw0GZecEY\nwFuqukdqWRF5BLhaVeel3OMq4ANV/cLbSpzGDABefdXSCC9fHs711q2zvvoNG6KbTZSsqclyrCxb\nZhkyW/Lkkza/fUFJtOmcqxyFGjNYAPQVkV4i0h4YDaRuyz0LODt4fDqQmKQ4ExgdzDbqA/QF5otI\nNxHpElR6J+AEIM8ttoujf3+L4G+9Fc71Eq2COAQCsM1HTj0V/ud/Mpf1LiLnykfGYBCMAVwIzAFe\nxQaE60Rksogk0pJNA7qJSD1wKTAhOHcJcC+wBHgIGBt8zN8beFJEFgPzgNmq+lC4L60w2rSxVbth\njRvEpYso2U9+YsGgpXnSqh4MnCsnGbuJoha3biKwDJENDdn1q2dy1VX27y9+kf+1wnTKKbZJzbhx\n6Z9fuhT+7d9g1ar4tGqcc6ZQ3UQuRZgzipYti3bBWXOuuAJuvLH5BHazZtnAlwcC58qDB4NW+OpX\n7U38vffyv1Ycu4nAdq3q0QNmzEj/vHcROVdePBi0Qvv2tvtZbW1+11GNbzAAax2kS2C3bh28+CIM\nGZL+POdc6fFg0EphdBW9/TbssEN8Nw3/5jctTUXyjlpgq46HDLEd4Jxz5cGDQSuFkcE0zq0C2J7A\n7oYbPn/cu4icKz8eDFrpqKPg+efzyycS92AAtoNWXR0sXGjff/opzJljrQbnXPnwYNBKu+xis4Be\neKH11yiFYNC+veVP+fWv7funn4YDDoA994y2Xs65cHkwyEO+4walEAwAzj0XHn3UEth5F5Fz5cmD\nQR4qJRjssosFhJtu8mDgXLnyFch5aGqybe7eeSf3LIOq0LkzrF5t2ULj7q23rFusa1dYscIXmzkX\nZ61ZgZxNCmvXjH32sTS0S5fCgAG5ndvUBDvvXBqBAGDvveF737PppB4InCs/HgzylJhimmswKJUu\nomS33QbbtkVdC+dcIfiYQZ5aO25QisGgbVtbJOecKz8eDPLU2sVnpRgMnHPly4NBnvbf3/L+NzRk\nLpvMg4FzLk48GORJxLqKnn02t/M8GDjn4iSrYCAiw0VkqYgsE5HxaZ5vLyLTRaReRGpFpCrpuYnB\n8ToRGRoc6yEiT4jIEhF5WUQuDu8lFd+xx+bWVbRtG7z+OvTtW7g6OedcLjIGAxFpA9wGDAMGAmeK\nyIEpxcYA76pqP+AWYEpw7gDgDKA/MAKYKiICbAF+pKoDgKOAcWmuWTJyHURubITddoNOnQpXJ+ec\ny0U2LYPBQL2qrlTVzcB0YFRKmVHAHcHjGUAi0/1J2J7JW1R1BVAPDFbVNaq6GEBVPwDqgO55vZII\nDRoEb7wBGzZkV967iJxzcZNNMOgOJA+PNvLFN+7PyqjqVmCjiHRNc+7q1HNFpDdwCDAvh3rHyg47\nwODB8Nxz2ZWvr4/nVpfOucqVzaKzdOtNU/NDNFemxXNFpBPWkrgkaCGkNWnSpM8eV1dXU11d3Xxt\nI5KYYnriiZnLLlvmLQPnXHhqamqoqanJ6xrZBINGoCrp+x5AU0qZBqAn0CQibYEuqrpeRBqD4184\nV0TaYYHgL6r6QEsVSA4GcXXssTB5cnZl6+steDjnXBhSPyRPzvbNKEk23UQLgL4i0ktE2gOjgZkp\nZWYBZwePTweeCB7PBEYHs436AH2B+cFz/wssUdXf5FzrGDrySFi0CD75JHNZHzNwzsVNxmAQjAFc\nCMwBXsUGhOtEZLKIjAyKTQO6iUg9cCkwITh3CXAvsAR4CBirqioixwBnAUNEZJGILBSR4WG/uGLq\n1An697fdz1qyZYtl/dxvv6JUyznnsuIprEN02WW2A9iECc2XeeMNqK6GVauKVi3nXIVpTQprX4Ec\nomzyFHkXkXMujjwYhOiYY2x6aUtpnj0YOOfiyINBiPbcE/bYA155pfkyHgycc3HkwSBkmVJTeDBw\nzsWRB4OQZRo38NXHzrk48tlEIVu+3GYLNTR8ca/gzZttCur770P79pFUzzlXAXw2UQzst5+tJUg3\ndfTNN6F7dw8Ezrn48WAQMpHmu4p8vMA5F1ceDAqguUFkDwbOubjyYFAA3jJwzpUaDwYF8OUv225m\n69Z9/rgHA+dcXHkwKIB27SyL6bPPfv64BwPnXFx5MCiQ1HGDTZugqQl6946sSs451ywPBgWSGgze\neAN69bItMp1zLm48GBTIEUfASy/Bxx/b995F5JyLMw8GBdKxIxx0EMwP9nXzfY+dc3GWVTAQkeEi\nslRElonI+DTPtxeR6SJSLyK1IlKV9NzE4HidiAxNOj5NRNaKyEvhvJT4SZ5i6i0D51ycZQwGItIG\nuA0YBgwEzhSRA1OKjQHeVdV+wC3AlODcAcAZQH9gBDBV5LOMPbcH1yxbyeMGHgycc3GWTctgMFCv\nqitVdTMwHRiVUmYUcEfweAYwJHh8ErZn8hZVXQHUB9dDVZ8B1udX/Xg75hiorYWtWz0YOOfiLZtg\n0B1oSPq+MTiWtoyqbgU2ikjXNOeuTnNu2erWzRLTzZ0L77wDVVWZz3HOuSi0y6JMujSoqTmlmyuT\nzbkZTZo06bPH1dXVVFdX53qJyBx7LNxxB/TpA23bRl0b51w5qqmpoaamJq9rZBMMGoHkz7Q9gKaU\nMg1AT6BJRNoCXVR1vYg0BsdbOjej5GBQao47DsaNsz0OnHOuEFI/JE+ePDnna2TTTbQA6CsivUSk\nPTAamJlSZhZwdvD4dOCJ4PFMYHQw26gP0BeYn3SekL71UDaOPdY2s/HdzZxzcZYxGARjABcCc4BX\nsQHhOhGZLCIjg2LTgG4iUg9cCkwIzl0C3AssAR4Cxia2LRORu4DngP1FZJWI/Ee4Ly0eeve2cQMf\nPHbOxZlve1kEt94Kw4bBAQdEXRPnXCVozbaXHgycc67M+B7IzjnnWsWDgXPOOQ8GzjnnPBg455zD\ng4Fzzjk8GDjnnMODgXPOOTwYOOecw4OBc845PBg455zDg4Fzzjk8GDjnnMODgXPOOTwYOOecI8tg\nICLDRWSpiCwTkfFpnm8vItNFpF5EakWkKum5icHxOhEZmu01nXPOFU/GYCAibYDbgGHAQOBMETkw\npdgY4F1V7QfcAkwJzh0AnAH0B0YAU8Vkc00Xsnw3zHaf5z/PcPnPM1rZtAwGA/WqulJVNwPTgVEp\nZUYBdwSPZwBDgscnYdtkblHVFUB9cL1srulC5n9s4fKfZ7j85xmtbIJBd6Ah6fvG4FjaMsGeyRtF\npGuac1cHx7K5pnPOuSLJJhik2zotdR/K5srketw551wE2mVRphGoSvq+B9CUUqYB6Ak0iUhboIuq\nrheRxuB46rmSxTU/I5LTVp6uBZMnT466CmXFf57h8p9ndLIJBguAviLSC3gLGA2cmVJmFnA2MA84\nHXgiOD4TuFNEbsa6gfoC87EWSaZrAuS8qbNzzrncZQwGqrpVRC4E5mBv4tNUtU5EJgMLVPVBYBrw\nFxGpB9Zhb+6o6hIRuRdYAmwGxqqqAmmvWYDX55xzLgti783OOecqWWxXIPuitHCJyAoReVFEFonI\n/KjrU2pEZJqIrBWRl5KO7SYic0TkNRGZLSJdoqxjqWjmZ3m1iDSKyMLga3iUdSwlItJDRJ4QkSUi\n8rKIXBwcz+n3M5bBwBelFcQ2oFpVB6nq4KgrU4Jux34fk00AHlPVA7BxsolFr1VpSvezBPgvVT00\n+Hqk2JUqYVuAH6nqAOAoYFzwfpnT72csgwG+KK0QhPj+f8eeqj4DrE85nLzY8g7g5KJWqkQ187OE\n9FPOXQaqukZVFwePPwDqsBmaOf1+xvXNwRelhU+B2SKyQETOjboyZWIPVV0L9gcJfCni+pS6cSKy\nWET+5F1urSMivYFDgLnAnrn8fsY1GPiitPAdraqHASdif3THRl0h55JMBfZT1UOANcB/RVyfkiMi\nnbB0QJcELYSc3jPjGgyyWejmchB8MkBV3wHuw7riXH7WisieACKyF/B2xPUpWar6jm6f2vhH4PAo\n61NqRKQdFgj+oqoPBIdz+v2MazD4bKGbiLTH1i3MjLhOJUtEOgafGhCRnYGhwCvR1qokCZ9vtc4E\nfhA8Pht4IPUE16zP/SyDN6uEU/Hfz1z9L7BEVX+TdCyn38/YrjMIppb9hu2L0q6PuEolS0T6YK0B\nxRYa3uk/z9yIyF1ANbA7sBa4Grgf+D8s5coq4HRV3RBVHUtFMz/Lb2B93duAFcAPE/3drmUicgzw\nT+Bl7G9cgSuxbA/3kuXvZ2yDgXPOueKJazeRc865IvJg4JxzzoOBc845DwbOOefwYOCccw4PBs45\n5/Bg4JxzDg8GzjnngP8PQgBaCP3yeMEAAAAASUVORK5CYII=\n"
                    }, 
                    "output_type": "display_data"
                }
            ], 
            "source": "%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.plot([np.mean(loss_values[i:i+5]) for i in range(len(loss_values))])\nplt.show()\n", 
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "## Evaluation", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        25\n          1       0.00      0.00      0.00        28\n          2       0.30      1.00      0.46        23\n          3       1.00      1.00      1.00        24\n\navg / total       0.31      0.47      0.35       100\n\n[[ 0  0 25  0]\n [ 0  0 28  0]\n [ 0  0 23  0]\n [ 0  0  0 24]]\nClassification accuracy: 0.470000\nLog Loss: 0.972129\n", 
                    "output_type": "stream"
                }
            ], 
            "source": "y_ = np.argmax(y_test[0:100],1) # ground truth\nprint metrics.classification_report(y_true= y_, y_pred= y_pred_lb)\nprint metrics.confusion_matrix(y_true= y_, y_pred= y_pred_lb)\nprint(\"Classification accuracy: %0.6f\" % metrics.accuracy_score(y_true= y_, y_pred= y_pred_lb) )\nprint(\"Log Loss: %0.6f\" % metrics.log_loss(y_true= y_, y_pred= y_pred, labels=range(4)) )", 
            "execution_count": 35, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "### Viz", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [], 
            "source": "!wget --output-document utils1.py http://deeplearning.net/tutorial/code/utils.py\nimport utils1\nfrom utils1 import tile_raster_images", 
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "outputs": [], 
            "source": "#from utils import tile_raster_images\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n%matplotlib inline\nimage = Image.fromarray(tile_raster_images(kernels_l1, img_shape=(5, 5) ,tile_shape=(4, 8), tile_spacing=(1, 1)))\n### Plot image\nplt.rcParams['figure.figsize'] = (18.0, 18.0)\nimgplot = plt.imshow(image)\nimgplot.set_cmap('gray')  ", 
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "outputs": [], 
            "source": "image = Image.fromarray(tile_raster_images(kernels_l2, img_shape=(5, 5) ,tile_shape=(4, 12), tile_spacing=(1, 1)))\n### Plot image\nplt.rcParams['figure.figsize'] = (18.0, 18.0)\nimgplot = plt.imshow(image)\nimgplot.set_cmap('gray')  ", 
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "outputs": [], 
            "source": "import numpy as np\nplt.rcParams['figure.figsize'] = (5.0, 5.0)\nsampleimage1 = X_test[3]\nplt.imshow(np.reshape(sampleimage1,[64,128]), cmap=\"gray\")", 
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "outputs": [], 
            "source": "# Launch the graph\nwith tf.Session() as sess:\n    sess.run(init)\n    saver = tf.train.Saver(tf.all_variables())\n    \n    # load previously trained model if appilcable\n    ckpt = tf.train.get_checkpoint_state(chk_directory)\n    if ckpt:\n        print \"loading model: \",ckpt.model_checkpoint_path\n        saver.restore(sess, ckpt.model_checkpoint_path)\n    ActivatedUnits1 = sess.run(convolve1,feed_dict={x:np.reshape(sampleimage1,[1,64*128],order='F'),keep_prob:1.0})\n    plt.figure(1, figsize=(20,20))\n    n_columns = 3\n    n_rows = 3\n    for i in range(9):\n        plt.subplot(n_rows, n_columns, i+1)\n        plt.title('Filter ' + str(i))\n        plt.imshow(ActivatedUnits1[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")", 
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": false, 
                "run_control": {
                    "read_only": false
                }
            }
        }, 
        {
            "source": "\n<h3>Authors:</h3>\n<article class=\"teacher\">\n<div class=\"teacher-image\" style=\"    float: left;\n    width: 115px;\n    height: 115px;\n    margin-right: 10px;\n    margin-bottom: 10px;\n    border: 1px solid #CCC;\n    padding: 3px;\n    border-radius: 3px;\n    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n<h4>Saeed Aghabozorgi</h4>\n<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is Sr. Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients\u2019 ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n</article>", 
            "metadata": {
                "button": false, 
                "deletable": true, 
                "new_sheet": false, 
                "collapsed": true, 
                "run_control": {
                    "read_only": false
                }
            }, 
            "cell_type": "markdown"
        }, 
        {
            "outputs": [], 
            "source": "", 
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }
        }
    ], 
    "nbformat_minor": 1
}