{
    "nbformat": 4, 
    "cells": [
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "# SETI CNN using TF and Binary DS"
        }, 
        {
            "cell_type": "code", 
            "execution_count": 1, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "import requests\nimport json\n#import ibmseti\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nimport pickle\nimport time\n#!sudo pip install sklearn\nfrom sklearn.metrics import confusion_matrix", 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "execution_count": 2, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "!wget --output-document SETI.zip  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n!unzip -o SETI.zip\nimport SETI", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "--2017-05-16 10:47:54--  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\nResolving ibm.box.com (ibm.box.com)... 107.152.26.197\nConnecting to ibm.box.com (ibm.box.com)|107.152.26.197|:443... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://ibm.ent.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip [following]\n--2017-05-16 10:47:55--  https://ibm.ent.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\nResolving ibm.ent.box.com (ibm.ent.box.com)... 107.152.25.211, 107.152.24.211\nConnecting to ibm.ent.box.com (ibm.ent.box.com)|107.152.25.211|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://public.boxcloud.com/d/1/HaVf1xlqEgqLrS9BUWEm_Ca7Ue6t4R2ImKX2bNBVZH6vdoy6Ou5BXFsvBihbASYl6WgIwHcNHiXrPX8hBJ4KyGjro9CuJgrfJHqPzJk-_9B6RO9ZKkPdHt3vHT3J9rDO-qWx1jrs3IEUgQ2vAL9r5QNgqhq-SSkIOV5S2nPZnR7ckQpqAWVlMo3qLItlaTtCxbseLwJB2yx3ZHP6znM3mPabSi7Mf7Jo6xvkcA6m8AhoOPvqXfXC-cpPcBzD0u97M2HwGvhJoquL39TXvEQvSwTK1jCr_AixvdRmt9okYOpqYAeJorhVmt2LoceeRmys84l7Q2wYiNQJ0uPjPaBfsFsMdOkaBgXG_WWfZbiEApcWPo-oIXbnaZZDkWDuamw5hov52iP21IxZX4GVJ4ClNFxVjGr4t3M2pyIJSbwdVhVWDvpHssk7q89wtrRfiMf5YZu9GNDOZmI1PyvD9AOj0WZfGNVUs-7oVI0LcSR_BktR-udjk7MCKOEeBBgP_2ZH8N3UzMZYAOw-HVUTfZS-n4Tz_oee7K-s0UzG7g0nhRKOOLURtC-2gVZanZzU0_55m71c4PVNXfRG1Url-CvPcdyM8pGfOt0X1fXu_-PK6eL7AuneESXWq0FE5LWdGedSgntmQV_LSSKzMFqR_t_1qMhy4TcNRIZ-rRWCWZo-jxBa6E9KX09Z0Swpq7wz3SgwLTScXU5QKPI4hNNT9BnPaZ8pTzl7ZFTj-_d0r34NFBv1UdlGJFUGV54LhY-_Wb9ihpKXtXjRvn7BhobVn1jCW8mzEQGzI1Yv9pNiQE4HGxkGLn1ffA6Og7NWhuBoO_ZX5CuGHLObPYW9fum-iG9xJKTs_sy26VMUjH0KzmlQ2L63k5uAxAq0uZ194HHp7yTnefmOIpt4Z8BaQ16aW8ncB5eKrYBtbc46GQXkwDR5bWrW34CRhg2-R8m68U5NwoPJr9bZk_9FNvsdtiZ4YD9dgjMJlJ4XdjoNWpnnmZfbH4h7vEigVhPL9ypSaIkPyPsH_BeU3Pa5eRJx6pEDas0cr5C0o8k5Y2JcXwNtka3J9szLQ44PTkxmDTyhTe2BcjO6e7FjjBz3j1YDog7pLj_wxjDyGpjG8W61cFpSF0LVw-LNWwYvk-rHAEVwUzujb9_HGAHJ6ejpt6DdzviQbFCQng../download [following]\n--2017-05-16 10:47:55--  https://public.boxcloud.com/d/1/HaVf1xlqEgqLrS9BUWEm_Ca7Ue6t4R2ImKX2bNBVZH6vdoy6Ou5BXFsvBihbASYl6WgIwHcNHiXrPX8hBJ4KyGjro9CuJgrfJHqPzJk-_9B6RO9ZKkPdHt3vHT3J9rDO-qWx1jrs3IEUgQ2vAL9r5QNgqhq-SSkIOV5S2nPZnR7ckQpqAWVlMo3qLItlaTtCxbseLwJB2yx3ZHP6znM3mPabSi7Mf7Jo6xvkcA6m8AhoOPvqXfXC-cpPcBzD0u97M2HwGvhJoquL39TXvEQvSwTK1jCr_AixvdRmt9okYOpqYAeJorhVmt2LoceeRmys84l7Q2wYiNQJ0uPjPaBfsFsMdOkaBgXG_WWfZbiEApcWPo-oIXbnaZZDkWDuamw5hov52iP21IxZX4GVJ4ClNFxVjGr4t3M2pyIJSbwdVhVWDvpHssk7q89wtrRfiMf5YZu9GNDOZmI1PyvD9AOj0WZfGNVUs-7oVI0LcSR_BktR-udjk7MCKOEeBBgP_2ZH8N3UzMZYAOw-HVUTfZS-n4Tz_oee7K-s0UzG7g0nhRKOOLURtC-2gVZanZzU0_55m71c4PVNXfRG1Url-CvPcdyM8pGfOt0X1fXu_-PK6eL7AuneESXWq0FE5LWdGedSgntmQV_LSSKzMFqR_t_1qMhy4TcNRIZ-rRWCWZo-jxBa6E9KX09Z0Swpq7wz3SgwLTScXU5QKPI4hNNT9BnPaZ8pTzl7ZFTj-_d0r34NFBv1UdlGJFUGV54LhY-_Wb9ihpKXtXjRvn7BhobVn1jCW8mzEQGzI1Yv9pNiQE4HGxkGLn1ffA6Og7NWhuBoO_ZX5CuGHLObPYW9fum-iG9xJKTs_sy26VMUjH0KzmlQ2L63k5uAxAq0uZ194HHp7yTnefmOIpt4Z8BaQ16aW8ncB5eKrYBtbc46GQXkwDR5bWrW34CRhg2-R8m68U5NwoPJr9bZk_9FNvsdtiZ4YD9dgjMJlJ4XdjoNWpnnmZfbH4h7vEigVhPL9ypSaIkPyPsH_BeU3Pa5eRJx6pEDas0cr5C0o8k5Y2JcXwNtka3J9szLQ44PTkxmDTyhTe2BcjO6e7FjjBz3j1YDog7pLj_wxjDyGpjG8W61cFpSF0LVw-LNWwYvk-rHAEVwUzujb9_HGAHJ6ejpt6DdzviQbFCQng../download\nResolving public.boxcloud.com (public.boxcloud.com)... 107.152.27.200\nConnecting to public.boxcloud.com (public.boxcloud.com)|107.152.27.200|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3288 (3.2K) [application/zip]\nSaving to: \u2018SETI.zip\u2019\n\n100%[======================================>] 3,288       --.-K/s   in 0s      \n\n2017-05-16 10:47:56 (192 MB/s) - \u2018SETI.zip\u2019 saved [3288/3288]\n\nArchive:  SETI.zip\n  inflating: SETI.py                 \n  inflating: __MACOSX/._SETI.py      \n"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "### Download data"
        }, 
        {
            "cell_type": "code", 
            "execution_count": 16, 
            "metadata": {
                "collapsed": false, 
                "scrolled": true
            }, 
            "source": "# The code was removed by DSX for sharing.", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "mkdir: cannot create directory \u2018SETI\u2019: File exists\n--2017-05-16 07:59:03--  https://ibm.box.com/shared/static/ww315shk648d3mt3ljbyl1jjte8nkmvj.gz\nResolving ibm.box.com (ibm.box.com)... 107.152.27.197\nConnecting to ibm.box.com (ibm.box.com)|107.152.27.197|:443... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://ibm.ent.box.com/shared/static/ww315shk648d3mt3ljbyl1jjte8nkmvj.gz [following]\n--2017-05-16 07:59:04--  https://ibm.ent.box.com/shared/static/ww315shk648d3mt3ljbyl1jjte8nkmvj.gz\nResolving ibm.ent.box.com (ibm.ent.box.com)... 107.152.27.211\nConnecting to ibm.ent.box.com (ibm.ent.box.com)|107.152.27.211|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://public.boxcloud.com/d/1/vwmUfztdh4QmWdfYswL7eipaptVpmn6C5AbrT43-wIpUTiOUoi4V1aJB9bkOEERz4lhq3wOum84AqRmVO-dz4MWsGrsMEiwtDYJ84mEXN-tBp21pxTQmQ6uLflkGMOB8J3LOR3FgzNzf5FKqSncd9AixmdhP8CD50Dny4nx_wKcQ8La9mmcFuCvcGvgkIPgxMrU4GOMYo9sFh4sVLV01nMFHUnGWV4CLrzcrLNxnguqAfqGxuCbz4uX9IYIUW81ScMspe0p2qQOoiAfIH2Y1SRpjC2F190XMCA6Ji2Qli4ug6jDN_10vHi9lCyH3F3idNMA2jEZz67E1AhfGz7YelOZNnylw49KCRTLy68SXGhBVHVpk-UBjspbpJLzaiOrN1eoiACCVDVmDjgdzjDvDWaJupctTz6kjdi60q4nBeVm8PKU2Q8cleWsbOw5aTaGjxJRgC2t5lrqqFZFEkRltVzFzimv9-Q2M5gUWJBuAJwEVIEzBw9tb-8d3efGm85Dyio0hkGlCS5hNlQnM6ouTxijJC9k5jm6tI7RbDtxJVW4Bou3jrswQ8ADBlDHHIk8brgkX0g_EBMZcYIDXmLrqpR9xH0eWWsr7qeJiARENUgrRmjvmFpTu1R1kJVBm7F3EpewM6p6Nq1aNDB5pvl2OyF2IB-vcLgHDuyjVUMWDkSadYHwcS2ge5fjrskis3M0cezUqrLJJlb-4Axwq2QXN86MKQ4VW3cdbrI-IPrAYAJxEgTPlLEIfFwxrcmJELc1ZVPjwuvn8KyS6FVjTizx1W1vaiAj8zUvt5yg0ZaMrvzkFeHKlcEmOR1YkmwcP20h5e-L_9NB-kbyKCWxzAow9mEWyCtQlBOa3x2yy5BXEOUPRm5xqDDqOnI4yS-wJnyhHFe1zs3phW_057bD7_-9i4_Hd7L-4bPkNSKYpvS-QgMmLC5YUhcw7A59DVc3Im1pV_KLZGpiSqiquG9mG0hfisGhtzUr0D5vgB7-0frG8ekcvov9MvAvqOzbZ9D9VqW-gh4Y8burD7sk2ITbGM3lvZsE4JGCEgBNCpuDmWu663ttW-FJe5hKKSnkrnAuPeQL3awAzXV69zpBwTBZNTOEEfM-Rlpuk01SnBlK_4Jk3vO2_JB-wC52rBH8AFDyCufDUw0bhm_wNmt4PdHqD4Ndt3y1fWNdQTXTuCEkMkmLjwO471vE./download [following]\n--2017-05-16 07:59:05--  https://public.boxcloud.com/d/1/vwmUfztdh4QmWdfYswL7eipaptVpmn6C5AbrT43-wIpUTiOUoi4V1aJB9bkOEERz4lhq3wOum84AqRmVO-dz4MWsGrsMEiwtDYJ84mEXN-tBp21pxTQmQ6uLflkGMOB8J3LOR3FgzNzf5FKqSncd9AixmdhP8CD50Dny4nx_wKcQ8La9mmcFuCvcGvgkIPgxMrU4GOMYo9sFh4sVLV01nMFHUnGWV4CLrzcrLNxnguqAfqGxuCbz4uX9IYIUW81ScMspe0p2qQOoiAfIH2Y1SRpjC2F190XMCA6Ji2Qli4ug6jDN_10vHi9lCyH3F3idNMA2jEZz67E1AhfGz7YelOZNnylw49KCRTLy68SXGhBVHVpk-UBjspbpJLzaiOrN1eoiACCVDVmDjgdzjDvDWaJupctTz6kjdi60q4nBeVm8PKU2Q8cleWsbOw5aTaGjxJRgC2t5lrqqFZFEkRltVzFzimv9-Q2M5gUWJBuAJwEVIEzBw9tb-8d3efGm85Dyio0hkGlCS5hNlQnM6ouTxijJC9k5jm6tI7RbDtxJVW4Bou3jrswQ8ADBlDHHIk8brgkX0g_EBMZcYIDXmLrqpR9xH0eWWsr7qeJiARENUgrRmjvmFpTu1R1kJVBm7F3EpewM6p6Nq1aNDB5pvl2OyF2IB-vcLgHDuyjVUMWDkSadYHwcS2ge5fjrskis3M0cezUqrLJJlb-4Axwq2QXN86MKQ4VW3cdbrI-IPrAYAJxEgTPlLEIfFwxrcmJELc1ZVPjwuvn8KyS6FVjTizx1W1vaiAj8zUvt5yg0ZaMrvzkFeHKlcEmOR1YkmwcP20h5e-L_9NB-kbyKCWxzAow9mEWyCtQlBOa3x2yy5BXEOUPRm5xqDDqOnI4yS-wJnyhHFe1zs3phW_057bD7_-9i4_Hd7L-4bPkNSKYpvS-QgMmLC5YUhcw7A59DVc3Im1pV_KLZGpiSqiquG9mG0hfisGhtzUr0D5vgB7-0frG8ekcvov9MvAvqOzbZ9D9VqW-gh4Y8burD7sk2ITbGM3lvZsE4JGCEgBNCpuDmWu663ttW-FJe5hKKSnkrnAuPeQL3awAzXV69zpBwTBZNTOEEfM-Rlpuk01SnBlK_4Jk3vO2_JB-wC52rBH8AFDyCufDUw0bhm_wNmt4PdHqD4Ndt3y1fWNdQTXTuCEkMkmLjwO471vE./download\nResolving public.boxcloud.com (public.boxcloud.com)... 107.152.26.200\nConnecting to public.boxcloud.com (public.boxcloud.com)|107.152.26.200|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 46077318 (44M) [application/octet-stream]\nSaving to: \u2018SETI/SETIds8.tar.gz\u2019\n\n100%[======================================>] 46,077,318  8.57MB/s   in 5.1s   \n\n2017-05-16 07:59:10 (8.55 MB/s) - \u2018SETI/SETIds8.tar.gz\u2019 saved [46077318/46077318]\n\nSETI/SETIds8/\nSETI/SETIds8/test-labels-idx1-ubyte.gz\nSETI/SETIds8/test-images-idx3-ubyte.gz\nSETI/SETIds8/train-images-idx3-ubyte.gz\nSETI/SETIds8/train-labels-idx1-ubyte.gz\n"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "### Load data"
        }, 
        {
            "cell_type": "code", 
            "execution_count": 3, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "SETIds = SETI.read_data_sets('SETI/SETIds9/', one_hot=True, validation_size=0)\nSETIds.train.num_examples", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Extracting SETI/SETIds9/train-images-idx3-ubyte.gz\nExtracting SETI/SETIds9/train-labels-idx1-ubyte.gz\nExtracting SETI/SETIds9/test-images-idx3-ubyte.gz\nExtracting SETI/SETIds9/test-labels-idx1-ubyte.gz\n"
                }, 
                {
                    "data": {
                        "text/plain": "694"
                    }, 
                    "execution_count": 3, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "cell_type": "code", 
            "execution_count": 4, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "SETIds.train.images.shape", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "(694, 131072)"
                    }, 
                    "execution_count": 4, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": false
            }, 
            "source": "## CNN"
        }, 
        {
            "cell_type": "code", 
            "execution_count": 5, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Parameters\nlearning_rate = 0.001\nmax_training_iters = 50\nbatch_size = 20\ndisplay_step = 10\n\n# Network Parameters\nn_input = 784 # MNIST data input (img shape: 28*28)\nn_classes = 4 \ndropout = 0.75 # Dropout, probability to keep units\n\nheight = 256 # height of the image in pixels -- 128\nwidth = 512 # width of the image in pixels -- 1536\nflat = width * height # number of pixels in one image  -196608\nclass_output = 4 # number of possible classifications for the problem", 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "execution_count": 6, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "x  = tf.placeholder(tf.float32, shape=[None, flat])\ny_ = tf.placeholder(tf.float32, shape=[None, class_output])", 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "execution_count": 7, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "x_image = tf.reshape(x, [-1,height,width,1]) \nx_image", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "<tf.Tensor 'Reshape:0' shape=(?, 256, 512, 1) dtype=float32>"
                    }, 
                    "execution_count": 7, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "#### Convolutional Layer 1"
        }, 
        {
            "cell_type": "code", 
            "execution_count": 8, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1))\nb_conv1 = tf.Variable(tf.constant(0.1, shape=[32])) # need 32 biases for 32 outputs\nconvolve1= tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1\nh_conv1 = tf.nn.relu(convolve1)\nh_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\nlayer1= h_pool1\nlayer1", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "<tf.Tensor 'MaxPool:0' shape=(?, 128, 256, 32) dtype=float32>"
                    }, 
                    "execution_count": 8, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "#### Convolutional Layer 2"
        }, 
        {
            "cell_type": "code", 
            "execution_count": 9, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))\nb_conv2 = tf.Variable(tf.constant(0.1, shape=[64])) #need 64 biases for 64 outputs\nconvolve2= tf.nn.conv2d(layer1, W_conv2, strides=[1, 1, 1, 1], padding='SAME')+ b_conv2\nh_conv2 = tf.nn.relu(convolve2)\nh_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\nlayer2= h_pool2\nlayer2", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "<tf.Tensor 'MaxPool_1:0' shape=(?, 64, 128, 64) dtype=float32>"
                    }, 
                    "execution_count": 9, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "#### Convolutional Layer 3"
        }, 
        {
            "cell_type": "code", 
            "execution_count": 10, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "W_conv3 = tf.Variable(tf.truncated_normal([5, 5, 64, 128], stddev=0.1))\nb_conv3 = tf.Variable(tf.constant(0.1, shape=[128])) #need 64 biases for 64 outputs\nconvolve3= tf.nn.conv2d(layer2, W_conv3, strides=[1, 1, 1, 1], padding='SAME')+ b_conv3\nh_conv3 = tf.nn.relu(convolve3)\nh_pool3 = tf.nn.max_pool(h_conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\nlayer3= h_pool3\nlayer3", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "<tf.Tensor 'MaxPool_2:0' shape=(?, 32, 64, 128) dtype=float32>"
                    }, 
                    "execution_count": 10, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "#### Fully Connected Layer"
        }, 
        {
            "cell_type": "code", 
            "execution_count": 11, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "dim = layer3.get_shape().as_list()\ndim", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[None, 32, 64, 128]"
                    }, 
                    "execution_count": 11, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "cell_type": "code", 
            "execution_count": 17, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "dims= dim[1]*dim[2]*dim[3]\nprv_layer_matrix = tf.reshape(layer3, [-1, dims])\nW_fc1 = tf.Variable(tf.truncated_normal([dims, 1024], stddev=0.1))\nb_fc1 = tf.Variable(tf.constant(0.1, shape=[1024])) # need 1024 biases for 1024 outputs\nfcl1  = tf.matmul(prv_layer_matrix, W_fc1) + b_fc1\nh_fc1 = tf.nn.relu(fcl1) # ???\nh_fc1\n", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "<tf.Tensor 'Relu_5:0' shape=(?, 1024) dtype=float32>"
                    }, 
                    "execution_count": 17, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "cell_type": "code", 
            "execution_count": 18, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "keep_prob = tf.placeholder(tf.float32)\nlayer_drop = tf.nn.dropout(h_fc1, keep_prob)", 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "#### Classification Layer"
        }, 
        {
            "cell_type": "code", 
            "execution_count": 19, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "W_fc2 = tf.Variable(tf.truncated_normal([1024, 4], stddev=0.1)) #1024 neurons\nb_fc2 = tf.Variable(tf.constant(0.1, shape=[4])) # 10 possibilities for classes [0,1,2,3]\nfcl2 = tf.matmul(layer_drop, W_fc2) + b_fc2\ny_CNN= tf.nn.softmax(fcl2)", 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "#### Training\n"
        }, 
        {
            "cell_type": "code", 
            "execution_count": 20, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_l4_conv), reduction_indices=[1]))\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_CNN, labels=y_))\ntrain_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)", 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "execution_count": 21, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "correct_prediction = tf.equal(tf.argmax(y_CNN,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))", 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "execution_count": 22, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# Initializing the variables\ninit = tf.initialize_all_variables()\n", 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# Launch the graph\nwith tf.Session() as sess:\n    sess.run(init)\n    step = 1\n    while step < max_training_iters:\n    # Keep training until reach max iterations\n        \n        start = time.time()\n\n        x_batch, y_batch = SETIds.train.next_batch(batch_size)\n        # Run optimization op (backprop)\n        #sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n        train_step.run(feed_dict={x: x_batch, y_: y_batch, keep_prob: dropout})\n\n        end = time.time()\n\n        if step % display_step == 0:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([cross_entropy, accuracy], feed_dict={x: x_batch,y_: y_batch,keep_prob: 1.})\n            #train_accuracy = accuracy.eval(feed_dict={x:x_batch, y_: y_batch,  keep_prob: 0.5})\n\n            print(\"Iter \" + str(step) + \\\n                \", Training time= \" + \"{:.5f}\".format(end - start) + \\\n                \", Minibatch Loss= \" +  \"{:.6f}\".format(loss) +  \\\n                \", Training Accuracy= \" + \"{:.5f}\".format(acc) )\n        step += 1\n    print(\"Optimization Finished!\")\n    \n    X_test = SETIds.test.images\n    y_test = SETIds.test.labels\n    \n    # Calculate accuracy for test images\n    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: X_test, y_: y_test, keep_prob: 1.}))\n        \n    # Find the labels of test set\n    y = sess.run(tf.argmax(y_l4_conv,1), feed_dict={x: X_test, y_: y_test, keep_prob: 1.})\n    \n    # lets save kernels\n    kernels_l1 = sess.run(tf.reshape(tf.transpose(W_conv1, perm=[2, 3, 0, 1]),[32,-1]))\n    kernels_l2 = sess.run(tf.reshape(tf.transpose(W_conv2, perm=[2, 3, 0, 1]),[32*64,-1]))", 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": false
            }, 
            "source": "## Evaluation"
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "y_ = np.argmax(y_test,1)\nconfusion_matrix(y_, y)", 
            "outputs": []
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "### Viz"
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "!wget --output-document utils1.py http://deeplearning.net/tutorial/code/utils.py\nimport utils1\nfrom utils1 import tile_raster_images", 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "#from utils import tile_raster_images\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n%matplotlib inline\nimage = Image.fromarray(tile_raster_images(kernels_l1, img_shape=(5, 5) ,tile_shape=(4, 8), tile_spacing=(1, 1)))\n### Plot image\nplt.rcParams['figure.figsize'] = (18.0, 18.0)\nimgplot = plt.imshow(image)\nimgplot.set_cmap('gray')  ", 
            "outputs": []
        }, 
        {
            "cell_type": "code", 
            "execution_count": 17, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "image = Image.fromarray(tile_raster_images(kernels_l2, img_shape=(5, 5) ,tile_shape=(4, 12), tile_spacing=(1, 1)))\n### Plot image\nplt.rcParams['figure.figsize'] = (18.0, 18.0)\nimgplot = plt.imshow(image)\nimgplot.set_cmap('gray')  ", 
            "outputs": [
                {
                    "output_type": "error", 
                    "traceback": [
                        "\u001b[1;31m\u001b[0m", 
                        "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[1;32m<ipython-input-17-8f5297516518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtile_raster_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernels_l2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mtile_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtile_spacing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m### Plot image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m18.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m18.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimgplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimgplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
                    ], 
                    "ename": "NameError", 
                    "evalue": "name 'Image' is not defined"
                }
            ]
        }, 
        {
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "outputs": []
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.0", 
            "language": "python", 
            "name": "python2-spark20"
        }, 
        "language_info": {
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }, 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "nbconvert_exporter": "python", 
            "mimetype": "text/x-python", 
            "pygments_lexer": "ipython2"
        }
    }, 
    "nbformat_minor": 0
}