{
    "metadata": {
        "language_info": {
            "file_extension": ".py", 
            "mimetype": "text/x-python", 
            "version": "2.7.11", 
            "pygments_lexer": "ipython2", 
            "name": "python", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }, 
            "nbconvert_exporter": "python"
        }, 
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.0", 
            "language": "python", 
            "name": "python2-spark20"
        }
    }, 
    "cells": [
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "# SETI CNN using TF and Binary DS"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 1, 
            "source": "import requests\nimport json\n#import ibmseti\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nimport pickle\nimport time\n#!sudo pip install sklearn\nfrom sklearn.metrics import confusion_matrix"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### import dataset reader"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "--2017-05-21 12:55:32--  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\nResolving ibm.box.com (ibm.box.com)... 107.152.26.197\nConnecting to ibm.box.com (ibm.box.com)|107.152.26.197|:443... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://ibm.ent.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip [following]\n--2017-05-21 12:55:32--  https://ibm.ent.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\nResolving ibm.ent.box.com (ibm.ent.box.com)... 107.152.26.211\nConnecting to ibm.ent.box.com (ibm.ent.box.com)|107.152.26.211|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://public.boxcloud.com/d/1/5DBj3hKre0cn6SpX6NjUPUDHrgD7gcUo9VYDxucBGaNaTivSNnisGQDfT_uQsSrxAY90dkf7XA1Wx09zifZdmve2ugb40IlOGZVrXW_7xeaUB0-muh3sstVptsC-I0W5vBGf3eE4onuQ56-sQ7mt67N2m-GQ0QToLLFyqiIM1TnFWOHFlGMp6IUr0pL7ARsHsT3D8S2_gOFTc0qgafvlvTT1RbAiP5gSA63SfWMMHfagDnJD7IQRUn6X_9WV-ZP_xlIRyh106UQkO_RMMspMY_kdfKid0kSMW7wOrosuzXb1sIIYNfWfwIrdfWf6hoH0YpcbjS58r_5zp7UrkNNrqlMoXO9LC1OFzbLKPsLpqEL_-j_eEkoHlQCCiyqbyypOupZQCuTWSWeM1U4pdvAPdKR2sc5CaYBiOa8hr3r_1770bvT8iC1gJ15RePh4ac6rCwff-eqEg-KevNi-eazg7Uzr39btyA8kNN9wMs3bM9Sm7_-lLevIL6MqvWfHpmksrLQwd0jNzqNq5miUPafHwfQ01-7TIdVEsQqBL4_PbhnKBmKqB2EObe3xrG0Y_glUDjZD_OC7MGPoVeZ2jzDgvMjs1lrH2HoofKQmZGy7whLeatGaNzHVOa7q3ZCGKPl1ODlvOWOR-Nu0rC0-uWatyW9_yYzMAjbcKOkH4cG9ZoKCl4rtBiHZ8ayd0xTp9WfzGr7Gj8Y-ADtXaaoSqTc7727nOyvHO_jtIkQu0KOljDvDJL0cgmvaK3AMY2GetHWoLCnYgEIPE_R9aZT8xvPt87gKnaDLI7_3d1Q3aHiyIAwbtTAvyY975IJb9TCkNixhhmzCH3K84TIfiJSljvtc22Po3AtPVHb0qxwioGdrLHRNJd3-B2TycC5POiuyZ1iCnVCy-_L1bfeWfEyut46qw9-BQrb4-wbIn5pyzFp6awXr0e34kkjyWDbXHXkDcUq7JEQhL03o0xnCibdIrlSPuJYivxr9Zg4JBNGHgxBfiCDelRmGkqLyd9-8qO1qaGtNil4e02iB5ORmRINy1PDFyhvu4xL4M2hyycOAvMSbcyiBdxmueFzGEKN_dRXTm8RGPAHxefs3rMRM2ebnhpWLagBiSFJIwfY08y7Q3bdEBci-B63PsNWOEnz6_cS8fQf94vMsKMvzMVMTT4pMN4RQBg../download [following]\n--2017-05-21 12:55:33--  https://public.boxcloud.com/d/1/5DBj3hKre0cn6SpX6NjUPUDHrgD7gcUo9VYDxucBGaNaTivSNnisGQDfT_uQsSrxAY90dkf7XA1Wx09zifZdmve2ugb40IlOGZVrXW_7xeaUB0-muh3sstVptsC-I0W5vBGf3eE4onuQ56-sQ7mt67N2m-GQ0QToLLFyqiIM1TnFWOHFlGMp6IUr0pL7ARsHsT3D8S2_gOFTc0qgafvlvTT1RbAiP5gSA63SfWMMHfagDnJD7IQRUn6X_9WV-ZP_xlIRyh106UQkO_RMMspMY_kdfKid0kSMW7wOrosuzXb1sIIYNfWfwIrdfWf6hoH0YpcbjS58r_5zp7UrkNNrqlMoXO9LC1OFzbLKPsLpqEL_-j_eEkoHlQCCiyqbyypOupZQCuTWSWeM1U4pdvAPdKR2sc5CaYBiOa8hr3r_1770bvT8iC1gJ15RePh4ac6rCwff-eqEg-KevNi-eazg7Uzr39btyA8kNN9wMs3bM9Sm7_-lLevIL6MqvWfHpmksrLQwd0jNzqNq5miUPafHwfQ01-7TIdVEsQqBL4_PbhnKBmKqB2EObe3xrG0Y_glUDjZD_OC7MGPoVeZ2jzDgvMjs1lrH2HoofKQmZGy7whLeatGaNzHVOa7q3ZCGKPl1ODlvOWOR-Nu0rC0-uWatyW9_yYzMAjbcKOkH4cG9ZoKCl4rtBiHZ8ayd0xTp9WfzGr7Gj8Y-ADtXaaoSqTc7727nOyvHO_jtIkQu0KOljDvDJL0cgmvaK3AMY2GetHWoLCnYgEIPE_R9aZT8xvPt87gKnaDLI7_3d1Q3aHiyIAwbtTAvyY975IJb9TCkNixhhmzCH3K84TIfiJSljvtc22Po3AtPVHb0qxwioGdrLHRNJd3-B2TycC5POiuyZ1iCnVCy-_L1bfeWfEyut46qw9-BQrb4-wbIn5pyzFp6awXr0e34kkjyWDbXHXkDcUq7JEQhL03o0xnCibdIrlSPuJYivxr9Zg4JBNGHgxBfiCDelRmGkqLyd9-8qO1qaGtNil4e02iB5ORmRINy1PDFyhvu4xL4M2hyycOAvMSbcyiBdxmueFzGEKN_dRXTm8RGPAHxefs3rMRM2ebnhpWLagBiSFJIwfY08y7Q3bdEBci-B63PsNWOEnz6_cS8fQf94vMsKMvzMVMTT4pMN4RQBg../download\nResolving public.boxcloud.com (public.boxcloud.com)... 107.152.25.200, 107.152.24.200\nConnecting to public.boxcloud.com (public.boxcloud.com)|107.152.25.200|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3288 (3.2K) [application/zip]\nSaving to: \u2018SETI.zip\u2019\n\n100%[======================================>] 3,288       --.-K/s   in 0s      \n\n2017-05-21 12:55:33 (651 MB/s) - \u2018SETI.zip\u2019 saved [3288/3288]\n\nArchive:  SETI.zip\n  inflating: SETI.py                 \n  inflating: __MACOSX/._SETI.py      \n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 13, 
            "source": "!wget --output-document SETI.zip  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n!unzip -o SETI.zip\nimport SETI"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Download data"
        }, 
        {
            "metadata": {
                "scrolled": true, 
                "collapsed": false
            }, 
            "cell_type": "raw", 
            "source": "# @hidden_cell\n!rm -r SETI/*\n!mkdir SETI\n!wget --output-document SETI/SETIds8.tar.gz https://ibm.box.com/shared/static/ww315shk648d3mt3ljbyl1jjte8nkmvj.gz\n#!unzip -o SETI/Archive.zip -d SETI/Archive\n!tar -xvf SETI/SETIds8.tar.gz "
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Load data"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Extracting MNIST_data/train-images-idx3-ubyte.gz\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 2, 
            "source": "from tensorflow.examples.tutorials.mnist import input_data\ndataset = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "test-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\r\ntest-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\r\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 15, 
            "source": "!ls SETI/SETI_ds_256x2048/"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Extracting SETI/SETI_ds_768x1024/train-images-idx3-ubyte.gz\nExtracting SETI/SETI_ds_768x1024/train-labels-idx1-ubyte.gz\nExtracting SETI/SETI_ds_768x1024/test-images-idx3-ubyte.gz\nExtracting SETI/SETI_ds_768x1024/test-labels-idx1-ubyte.gz\n", 
                    "name": "stdout"
                }, 
                {
                    "metadata": {}, 
                    "execution_count": 16, 
                    "data": {
                        "text/plain": "694"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 16, 
            "source": "dataset = SETI.read_data_sets('SETI/SETI_ds_768x1024/', one_hot=True, validation_size=0)\ndataset.train.num_examples"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "execution_count": 3, 
                    "data": {
                        "text/plain": "(55000, 784)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 3, 
            "source": "dataset.train.images.shape"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "markdown", 
            "source": "## CNN"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 4, 
            "source": "# Parameters\nlearning_rate = 0.0001\n#max_training_iters = 500\ntraining_epochs = 3\nbatch_size = 20\ndisplay_step = 100\n\n# Network Parameters\n\nn_classes = 10 # number of possible classifications for the problem\ndropout = 0.75 # Dropout, probability to keep units\n\nheight = 28 # height of the image in pixels -- 128\nwidth = 28 # width of the image in pixels -- 1536\nn_input = width * height # number of pixels in one image  -196608\n"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 5, 
            "source": "x  = tf.placeholder(tf.float32, shape=[None, n_input])\ny_ = tf.placeholder(tf.float32, shape=[None, n_classes])"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "execution_count": 6, 
                    "data": {
                        "text/plain": "<tf.Tensor 'Reshape:0' shape=(?, 28, 28, 1) dtype=float32>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 6, 
            "source": "x_image = tf.reshape(x, [-1,height,width,1]) \nx_image"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "#### Convolutional Layer 1"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "execution_count": 7, 
                    "data": {
                        "text/plain": "<tf.Tensor 'MaxPool:0' shape=(?, 14, 14, 32) dtype=float32>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 7, 
            "source": "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1))\nb_conv1 = tf.Variable(tf.constant(0.1, shape=[32])) # need 32 biases for 32 outputs\nconvolve1 = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1\nh_conv1 = tf.nn.relu(convolve1)\nh_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\nlayer1= h_pool1\nlayer1"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "#### Convolutional Layer 2"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "execution_count": 8, 
                    "data": {
                        "text/plain": "<tf.Tensor 'MaxPool_1:0' shape=(?, 7, 7, 64) dtype=float32>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 8, 
            "source": "W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))\nb_conv2 = tf.Variable(tf.constant(0.1, shape=[64])) #need 64 biases for 64 outputs\nconvolve2= tf.nn.conv2d(layer1, W_conv2, strides=[1, 1, 1, 1], padding='SAME')+ b_conv2\nh_conv2 = tf.nn.relu(convolve2)\nh_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\nlayer2= h_pool2\nlayer2"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "#### Convolutional Layer 3"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "execution_count": 9, 
                    "data": {
                        "text/plain": "<tf.Tensor 'MaxPool_2:0' shape=(?, 2, 2, 128) dtype=float32>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 9, 
            "source": "W_conv3 = tf.Variable(tf.truncated_normal([5, 5, 64, 128], stddev=0.1))\nb_conv3 = tf.Variable(tf.constant(0.1, shape=[128])) #need 64 biases for 64 outputs\nconvolve3= tf.nn.conv2d(layer2, W_conv3, strides=[1, 1, 1, 1], padding='SAME')+ b_conv3\nh_conv3 = tf.nn.relu(convolve3)\nh_pool3 = tf.nn.max_pool(h_conv3, ksize=[1, 4, 4, 1], strides=[1, 4, 4, 1], padding='SAME') #max_pool_2x2\nlayer3= h_pool3\nlayer3"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "#### Convolutional Layer 4"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "error", 
                    "traceback": [
                        "\u001b[1;31m\u001b[0m", 
                        "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[1;32m<ipython-input-10-2f409256f413>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mW_conv4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb_conv4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#need 64 biases for 64 outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconvolve4\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_conv4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mb_conv4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mh_conv4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvolve4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mh_pool4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_conv4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#max_pool_2x2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[0;32m    392\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                                 \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m    395\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    702\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    703\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                            op_def=op_def)\n\u001b[0m\u001b[0;32m    705\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2260\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2262\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2263\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2264\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1700\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[0;32m   1701\u001b[0m                          % op.type)\n\u001b[1;32m-> 1702\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1703\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m     raise RuntimeError(\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/ops/common_shapes.pyc\u001b[0m in \u001b[0;36mconv2d_shape\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    244\u001b[0m   out_rows, out_cols = get2d_conv_output_size(in_rows, in_cols, filter_rows,\n\u001b[0;32m    245\u001b[0m                                               \u001b[0mfilter_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m                                               padding)\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_out\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/ops/common_shapes.pyc\u001b[0m in \u001b[0;36mget2d_conv_output_size\u001b[1;34m(input_height, input_width, filter_height, filter_width, row_stride, col_stride, padding_type)\u001b[0m\n\u001b[0;32m    182\u001b[0m   return get_conv_output_size((input_height, input_width),\n\u001b[0;32m    183\u001b[0m                               \u001b[1;33m(\u001b[0m\u001b[0mfilter_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                               (row_stride, col_stride), padding_type)\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/ops/common_shapes.pyc\u001b[0m in \u001b[0;36mget_conv_output_size\u001b[1;34m(input_size, filter_size, strides, padding_type)\u001b[0m\n\u001b[0;32m    147\u001b[0m          zip(filter_size, input_size)):\n\u001b[0;32m    148\u001b[0m     raise ValueError(\"Filter must not be larger than the input: \"\n\u001b[1;32m--> 149\u001b[1;33m                      \"Filter: %r Input: %r\" % (filter_size, input_size))\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mpadding_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"VALID\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;31mValueError\u001b[0m: Filter must not be larger than the input: Filter: (5, 5) Input: (2, 2)"
                    ], 
                    "evalue": "Filter must not be larger than the input: Filter: (5, 5) Input: (2, 2)", 
                    "ename": "ValueError"
                }
            ], 
            "execution_count": 10, 
            "source": "W_conv4 = tf.Variable(tf.truncated_normal([5, 5, 128, 256], stddev=0.1))\nb_conv4 = tf.Variable(tf.constant(0.1, shape=[256])) #need 64 biases for 64 outputs\nconvolve4= tf.nn.conv2d(layer3, W_conv4, strides=[1, 1, 1, 1], padding='SAME')+ b_conv4\nh_conv4 = tf.nn.relu(convolve4)\nh_pool4 = tf.nn.max_pool(h_conv4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\nlayer4= h_pool4\nlayer4"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "#### Fully Connected Layer 1"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "execution_count": 22, 
                    "data": {
                        "text/plain": "[None, 7, 7, 64]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 22, 
            "source": "input_layer = layer2\ndim = input_layer.get_shape().as_list()\ndim"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "execution_count": 23, 
                    "data": {
                        "text/plain": "3136"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 23, 
            "source": "dim[1]*dim[2]*dim[3]"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "execution_count": 24, 
                    "data": {
                        "text/plain": "<tf.Tensor 'Relu_3:0' shape=(?, 1024) dtype=float32>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 24, 
            "source": "dims= dim[1]*dim[2]*dim[3]\nnodes1 = 1024\nprv_layer_matrix = tf.reshape(input_layer, [-1, dims])\nW_fc1 = tf.Variable(tf.truncated_normal([dims, nodes1], stddev=0.1))\nb_fc1 = tf.Variable(tf.constant(0.1, shape=[nodes1])) # need 1024 biases for 1024 outputs\nfcl1  = tf.matmul(prv_layer_matrix, W_fc1) + b_fc1\nh_fc1 = tf.nn.relu(fcl1) # ???\nh_fc1\n"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "#### Fully Connected Layer 2"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "execution_count": 25, 
                    "data": {
                        "text/plain": "<tf.Tensor 'Relu_4:0' shape=(?, 256) dtype=float32>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 25, 
            "source": "nodes2 = 256\nW_fc2 = tf.Variable(tf.truncated_normal([h_fc1.get_shape().as_list()[1], nodes2], stddev=0.1))\nb_fc2 = tf.Variable(tf.constant(0.1, shape=[nodes2])) \nfcl2  = tf.matmul(h_fc1, W_fc2) + b_fc2\nh_fc2 = tf.nn.relu(fcl2) # ???\nh_fc2"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 26, 
            "source": "keep_prob = tf.placeholder(tf.float32)\nlayer_drop = tf.nn.dropout(h_fc2, keep_prob)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "#### Softmax Layer"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 28, 
            "source": "W_fc = tf.Variable(tf.truncated_normal([nodes2, n_classes], stddev=0.1)) #1024 neurons\nb_fc = tf.Variable(tf.constant(0.1, shape=[n_classes])) # 10 possibilities for classes [0,1,2,3]\nfcl = tf.matmul(layer_drop, W_fc) + b_fc\ny_CNN= tf.nn.softmax(fcl)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "#### Training\n"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 29, 
            "source": "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_l4_conv), reduction_indices=[1]))\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_CNN, labels=y_))\ntrain_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 30, 
            "source": "correct_prediction = tf.equal(tf.argmax(y_CNN,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 31, 
            "source": "# Initializing the variables\ninit = tf.initialize_all_variables()\n"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "raw", 
            "source": "# Launch the graph\nwith tf.Session() as sess:\n    # load previously trained model if appilcable\n    ckpt = tf.train.get_checkpoint_state('SETI/save')\n    if ckpt:\n        ckpt = tf.train.get_checkpoint_state(checkpoint_path)\n        print \"loading model: \",ckpt.model_checkpoint_path\n        saver.restore(sess, ckpt.model_checkpoint_path)\n    \n    \n    X_test = dataset.test.images\n    y_test = dataset.test.labels\n    sess.run(init)\n    saver = tf.train.Saver(tf.all_variables())\n    step = 1\n    while step < max_training_iters:\n    # Keep training until reach max iterations\n        \n        start = time.time()\n\n        x_batch, y_batch = dataset.train.next_batch(batch_size)\n        # Run optimization op (backprop)\n        #sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n        train_step.run(feed_dict={x: x_batch, y_: y_batch, keep_prob: dropout})\n\n        end = time.time()\n\n        if step % display_step == 0:\n            # Save model\n            print (\"model saved to {}\".format(checkpoint_path))\n            saver.save(sess, checkpoint_path, global_step = epoch)\n            \n            \n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([cross_entropy, accuracy], feed_dict={x: x_batch,y_: y_batch,keep_prob: 1.})\n            #train_accuracy = accuracy.eval(feed_dict={x:x_batch, y_: y_batch,  keep_prob: 0.5})\n            \n            \n            test_accuracy = sess.run(accuracy, feed_dict={x: X_test[0:100], y_: y_test[0:100], keep_prob: 1.})\n            \n            print(\"Iter \" + str(step) + \\\n                \", Training time= \" + \"{:.5f}\".format(end - start) + \\\n                \", Minibatch Loss= \" +  \"{:.6f}\".format(loss) +  \\\n                \", Training Accuracy= \" + \"{:.5f}\".format(acc)  + \\\n                \", Test Accuracy= \" + \"{:.5f}\".format(test_accuracy) )\n        step += 1\n    print(\"Optimization Finished!\")\n    \n    \n    \n    # Calculate accuracy for test images\n    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: X_test[0:100], y_: y_test[0:100], keep_prob: 1.}))\n        \n    # Find the labels of test set\n    #y = sess.run(tf.argmax(y_l4_conv,1), feed_dict={x: X_test[0:100], y_: y_test[0:100], keep_prob: 1.})\n    \n    # lets save kernels\n    #kernels_l1 = sess.run(tf.reshape(tf.transpose(W_conv1, perm=[2, 3, 0, 1]),[32,-1]))\n    #kernels_l2 = sess.run(tf.reshape(tf.transpose(W_conv2, perm=[2, 3, 0, 1]),[32*64,-1]))"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "execution_count": 32, 
                    "data": {
                        "text/plain": "model_checkpoint_path: \"MNIST/save/model.ckpt-2\"\nall_model_checkpoint_paths: \"MNIST/save/model.ckpt-0\"\nall_model_checkpoint_paths: \"MNIST/save/model.ckpt-1\"\nall_model_checkpoint_paths: \"MNIST/save/model.ckpt-2\""
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 32, 
            "source": "ckpt = tf.train.get_checkpoint_state('MNIST/save')\nckpt"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "execution_count": 33, 
                    "data": {
                        "text/plain": "u'MNIST/save/model.ckpt-2'"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "execution_count": 33, 
            "source": "ckpt.model_checkpoint_path"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 34, 
            "source": "#!mkdir MNIST/save"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "total 1308528\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users 39298136 May 21 16:04 model.ckpt-5\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users   107522 May 21 16:04 model.ckpt-5.meta\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users 39298136 May 21 16:05 model.ckpt-6\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users   107522 May 21 16:05 model.ckpt-6.meta\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users 39298136 May 21 16:06 model.ckpt-7\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users   107522 May 21 16:06 model.ckpt-7.meta\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users 39298136 May 21 16:07 model.ckpt-8\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users   107522 May 21 16:07 model.ckpt-8.meta\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users 39298136 May 21 16:08 model.ckpt-9\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users   107522 May 21 16:08 model.ckpt-9.meta\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users 83744256 May 22 13:58 model.ckpt-1\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users   171844 May 22 13:58 model.ckpt-1.meta\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users 83744256 May 22 13:59 model.ckpt-2\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users   171844 May 22 13:59 model.ckpt-2.meta\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users 81486039 May 22 14:23 model.ckpt-0\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users       81 May 22 14:23 checkpoint\r\n-rw-r----- 1 sd22-2e55b7df66e8c3-b01c69100280 users   205790 May 22 14:23 model.ckpt-0.meta\r\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 38, 
            "source": "!ls -ltr MNIST/save"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "loading model:  MNIST/save/model.ckpt-2\nIter 0, Training time= 0.15281, Minibatch Loss= 2.381561, Training Accuracy= 0.05000, Test Accuracy= 0.25000\nIter 100, Training time= 0.02251, Minibatch Loss= 1.960578, Training Accuracy= 0.55000, Test Accuracy= 0.75000\nIter 200, Training time= 0.04464, Minibatch Loss= 1.744447, Training Accuracy= 0.75000, Test Accuracy= 0.80000\nIter 300, Training time= 0.02412, Minibatch Loss= 1.740589, Training Accuracy= 0.75000, Test Accuracy= 0.95000\nIter 400, Training time= 0.02501, Minibatch Loss= 1.758932, Training Accuracy= 0.70000, Test Accuracy= 0.95000\nIter 500, Training time= 0.02403, Minibatch Loss= 1.724313, Training Accuracy= 0.70000, Test Accuracy= 0.95000\nIter 600, Training time= 0.02412, Minibatch Loss= 1.750386, Training Accuracy= 0.70000, Test Accuracy= 1.00000\nIter 700, Training time= 0.02404, Minibatch Loss= 1.503368, Training Accuracy= 1.00000, Test Accuracy= 1.00000\nIter 800, Training time= 0.02294, Minibatch Loss= 1.592016, Training Accuracy= 0.85000, Test Accuracy= 0.95000\nIter 900, Training time= 0.02514, Minibatch Loss= 1.518575, Training Accuracy= 0.95000, Test Accuracy= 1.00000\nIter 1000, Training time= 0.02385, Minibatch Loss= 1.541418, Training Accuracy= 0.90000, Test Accuracy= 1.00000\nIter 1100, Training time= 0.02384, Minibatch Loss= 1.464530, Training Accuracy= 1.00000, Test Accuracy= 0.95000\nIter 1200, Training time= 0.02366, Minibatch Loss= 1.551017, Training Accuracy= 0.90000, Test Accuracy= 1.00000\nIter 1300, Training time= 0.02423, Minibatch Loss= 1.471000, Training Accuracy= 1.00000, Test Accuracy= 1.00000\nIter 1400, Training time= 0.02579, Minibatch Loss= 1.578167, Training Accuracy= 0.85000, Test Accuracy= 1.00000\nIter 1500, Training time= 0.03165, Minibatch Loss= 1.465825, Training Accuracy= 1.00000, Test Accuracy= 1.00000\nIter 1600, Training time= 0.02479, Minibatch Loss= 1.526848, Training Accuracy= 0.95000, Test Accuracy= 1.00000\nIter 1700, Training time= 0.02465, Minibatch Loss= 1.582130, Training Accuracy= 0.90000, Test Accuracy= 1.00000\nIter 1800, Training time= 0.02342, Minibatch Loss= 1.511376, Training Accuracy= 0.95000, Test Accuracy= 1.00000\nIter 1900, Training time= 0.02428, Minibatch Loss= 1.522159, Training Accuracy= 0.95000, Test Accuracy= 1.00000\nIter 2000, Training time= 0.04094, Minibatch Loss= 1.509785, Training Accuracy= 0.95000, Test Accuracy= 1.00000\nIter 2100, Training time= 0.02354, Minibatch Loss= 1.480023, Training Accuracy= 1.00000, Test Accuracy= 0.95000\nIter 2200, Training time= 0.02422, Minibatch Loss= 1.484298, Training Accuracy= 1.00000, Test Accuracy= 0.95000\nIter 2300, Training time= 0.02414, Minibatch Loss= 1.516402, Training Accuracy= 0.95000, Test Accuracy= 1.00000\nIter 2400, Training time= 0.02292, Minibatch Loss= 1.512065, Training Accuracy= 0.95000, Test Accuracy= 1.00000\nIter 2500, Training time= 0.02361, Minibatch Loss= 1.464276, Training Accuracy= 1.00000, Test Accuracy= 1.00000\nIter 2600, Training time= 0.02344, Minibatch Loss= 1.512437, Training Accuracy= 0.95000, Test Accuracy= 1.00000\nIter 2700, Training time= 0.02336, Minibatch Loss= 1.485535, Training Accuracy= 0.95000, Test Accuracy= 0.95000\nmodel saved to MNIST/save/model.ckpt\nEpoch: 0001 cost= 1.565841576\nIter 0, Training time= 0.02365, Minibatch Loss= 1.521204, Training Accuracy= 0.90000, Test Accuracy= 1.00000\nIter 100, Training time= 0.02303, Minibatch Loss= 1.461272, Training Accuracy= 1.00000, Test Accuracy= 0.95000\nIter 200, Training time= 0.02284, Minibatch Loss= 1.461874, Training Accuracy= 1.00000, Test Accuracy= 0.95000\nIter 300, Training time= 0.02342, Minibatch Loss= 1.560286, Training Accuracy= 0.90000, Test Accuracy= 1.00000\nIter 400, Training time= 0.02353, Minibatch Loss= 1.462404, Training Accuracy= 1.00000, Test Accuracy= 1.00000\n", 
                    "name": "stdout"
                }, 
                {
                    "output_type": "error", 
                    "traceback": [
                        "\u001b[1;31m\u001b[0m", 
                        "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)", 
                        "\u001b[1;32m<ipython-input-37-190a519ee03a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mtrain_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m#assert( loss < 1000000 ) # make sure it is not NaN or Inf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3531\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3532\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3533\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 372\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    373\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 636\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    637\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 708\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    709\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    713\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/bluemix_jupyter_bundle.v44/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ], 
                    "evalue": "", 
                    "ename": "KeyboardInterrupt"
                }
            ], 
            "execution_count": 37, 
            "source": "checkpoint_path = 'MNIST/save/model.ckpt'\n\n# Launch the graph\nwith tf.Session() as sess:\n\n    \n    X_test = dataset.test.images\n    y_test = dataset.test.labels\n    sess.run(init)\n    saver = tf.train.Saver(tf.all_variables())\n    \n    # load previously trained model if appilcable\n    ckpt = tf.train.get_checkpoint_state('MNIST/save')\n    if ckpt:\n        print \"loading model: \",ckpt.model_checkpoint_path\n        #saver.restore(sess, ckpt.model_checkpoint_path)\n    \n    \n    #step = 0\n    num_examples = dataset.train.num_examples\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_loss = 0.\n        avg_accuracy = 0.\n        #dataset.shuffle_data()\n        total_batch = int(num_examples / batch_size)\n        # print total_batch\n        # Loop over all batches\n        for step in range(total_batch):\n            start = time.time()\n            x_batch, y_batch = dataset.train.next_batch(batch_size)\n            train_step.run(feed_dict={x: x_batch, y_: y_batch, keep_prob: dropout})\n            loss, acc = sess.run([cross_entropy, accuracy], feed_dict={x: x_batch,y_: y_batch,keep_prob: 1.})\n            #assert( loss < 1000000 ) # make sure it is not NaN or Inf\n            #assert( accuracy < 1000000 ) # make sure it is not NaN or Inf\n            \n            end = time.time()\n            \n            avg_loss += loss / total_batch\n            \n            if step % display_step == 0:\n\n                \n                # Calculate batch loss and accuracy\n                loss, acc = sess.run([cross_entropy, accuracy], feed_dict={x: x_batch,y_: y_batch,keep_prob: 1.})\n                #train_accuracy = accuracy.eval(feed_dict={x:x_batch, y_: y_batch,  keep_prob: 0.5})\n\n                test_accuracy = sess.run(accuracy, feed_dict={x: X_test[0:20], y_: y_test[0:20], keep_prob: 1.})\n\n                print(\"Iter \" + str(step) + \\\n                    \", Training time= \" + \"{:.5f}\".format(end - start) + \\\n                    \", Minibatch Loss= \" +  \"{:.6f}\".format(loss) +  \\\n                    \", Training Accuracy= \" + \"{:.5f}\".format(acc)  + \\\n                    \", Test Accuracy= \" + \"{:.5f}\".format(test_accuracy) )\n        \n        # save model every 1 epochs\n        if epoch >= 0 and epoch % 1 == 0:\n            # Save model\n            print (\"model saved to {}\".format(checkpoint_path))\n            saver.save(sess, checkpoint_path, global_step = epoch)\n\n            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_loss) \n\n    print(\"Optimization Finished!\")\n\n    \n    \n    # Calculate accuracy for test images\n    #print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: X_test[0:30], y_: y_test[0:30], keep_prob: 1.}))\n        \n    # Find the labels of test set\n    #y = sess.run(tf.argmax(y_l4_conv,1), feed_dict={x: X_test[0:100], y_: y_test[0:100], keep_prob: 1.})\n    \n    # lets save kernels\n    #kernels_l1 = sess.run(tf.reshape(tf.transpose(W_conv1, perm=[2, 3, 0, 1]),[32,-1]))\n    #kernels_l2 = sess.run(tf.reshape(tf.transpose(W_conv2, perm=[2, 3, 0, 1]),[32*64,-1]))"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "markdown", 
            "source": "## Evaluation"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": "y_ = np.argmax(y_test,1)\nconfusion_matrix(y_, y)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Viz"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": "!wget --output-document utils1.py http://deeplearning.net/tutorial/code/utils.py\nimport utils1\nfrom utils1 import tile_raster_images"
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": "#from utils import tile_raster_images\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n%matplotlib inline\nimage = Image.fromarray(tile_raster_images(kernels_l1, img_shape=(5, 5) ,tile_shape=(4, 8), tile_spacing=(1, 1)))\n### Plot image\nplt.rcParams['figure.figsize'] = (18.0, 18.0)\nimgplot = plt.imshow(image)\nimgplot.set_cmap('gray')  "
        }, 
        {
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "error", 
                    "traceback": [
                        "\u001b[1;31m\u001b[0m", 
                        "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[1;32m<ipython-input-17-8f5297516518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtile_raster_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernels_l2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mtile_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtile_spacing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m### Plot image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m18.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m18.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimgplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimgplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
                    ], 
                    "evalue": "name 'Image' is not defined", 
                    "ename": "NameError"
                }
            ], 
            "execution_count": 17, 
            "source": "image = Image.fromarray(tile_raster_images(kernels_l2, img_shape=(5, 5) ,tile_shape=(4, 12), tile_spacing=(1, 1)))\n### Plot image\nplt.rcParams['figure.figsize'] = (18.0, 18.0)\nimgplot = plt.imshow(image)\nimgplot.set_cmap('gray')  "
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": ""
        }
    ], 
    "nbformat": 4, 
    "nbformat_minor": 0
}